[{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"the-framework","dir":"","previous_headings":"","what":"The framework","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"Repository R package snreg. R commands snreg snsf estimate models skew-normal errors written maintained Oleg Badunenko (oleg.badunenko@brunel.ac.uk). details discussed Badunenko, O., & Henderson, D. J. (2023). Production analysis asymmetric noise. Journal Productivity Analysis, 61(1), 1â€“18. DOI","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"id_1-install-the-devtools-package","dir":"","previous_headings":"","what":"1. Install the devtools package","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"Install devtools CRAN (havenâ€™t already):","code":"install.packages(\"devtools\")"},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"id_2-install-the-package-from-github","dir":"","previous_headings":"","what":"2. Install the package from GitHub","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"Install snreg package GitHub. code, installing snreg package created OlegBadunenko.","code":"library(devtools) install_github(\"OlegBadunenko/snreg\")"},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"id_3-load-the-installed-package","dir":"","previous_headings":"","what":"3. Load the installed package","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"","code":"library(snreg)"},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"bulb-notes--tips","dir":"","previous_headings":"","what":"ðŸ’¡ Notes & Tips","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"Works identically across R, RStudio, Windows, Mac, Linux. GitHub packages may already available environments like npsf. installation fails, common causes include missing build tools, incorrect repo names, network restrictions.","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"data","dir":"","previous_headings":"","what":"Data","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"data frame containing selected variables 500 U.S. commercial banks, randomly sampled approximately 5000 banks, based dataset Koetter et al.Â (2012) year 2007. dataset provided solely illustration pedagogical purposes suitable empirical research. {r data, eval = TRUE}   library(snreg)   library(tidyverse)   data(banks07, package = \"snreg\")   head(banks07)","code":""},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"specification","dir":"","previous_headings":"","what":"Specification","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"Define specification (formula) used: {r formula, eval = TRUE} # Translog cost function specification spe.tl <- log(TC) ~ (log(Y1) + log(Y2) + log(W1) + log(W2))^2 +   (0.5 * log(Y1)^2) + (0.5 * log(Y2)^2) +   (0.5 * log(W1)^2) + (0.5 * log(W2)^2)","code":""},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"linear-regression-via-mle","dir":"","previous_headings":"","what":"Linear Regression via MLE","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"estimate simple OLS using MLE ```{r lmmle, eval = TRUE} # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”- # Specification 1: homoskedastic noise (ln.var.v = NULL) # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”- formSV <- NULL m1 <- lm.mle( formula = spe.tl, data = banks07, ln.var.v = formSV ) coef(m1)","code":""},{"path":[]},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"id_--1","dir":"","previous_headings":"","what":"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”-","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"formSV <- ~ log(TA) m2 <- lm.mle( formula = spe.tl, data = banks07, ln.var.v = formSV ) coef(m2)","code":"## Linear Regression with Skew-Normal Errors  > `snreg` fits a linear regression model where the disturbance term follows a skew-normal distribution.  ```{r snreg, eval=TRUE} # ------------------------------------------------------------- # Specification 1: homoskedastic & symmetric noise # ------------------------------------------------------------- formSV <- NULL     # variance equation formSK <- NULL     # skewness equation  m1 <- snreg(   formula  = spe.tl,   data     = banks07,   ln.var.v = formSV,   skew.v   = formSK )  coef(m1)   # ------------------------------------------------------------- # Specification 2: heteroskedastic + skewed noise # ------------------------------------------------------------- formSV <- ~ log(TA)   # heteroskedasticity in v formSK <- ~ ER        # skewness driven by equity ratio  m2 <- snreg(   formula  = spe.tl,   data     = banks07,   ln.var.v = formSV,   skew.v   = formSK )  coef(m2)"},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"stochastic-frontier-model-with-a-skew-normally-distributed-error-term","dir":"","previous_headings":"","what":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"snsf performs maximum likelihood estimation parameters technical cost efficiencies Stochastic Frontier Model skew-normally distributed error term. ```{r snsf, eval=TRUE} myprod <- FALSE","code":""},{"path":[]},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"id_--3","dir":"","previous_headings":"","what":"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”-","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"formSV <- NULL # variance equation formSK <- NULL # skewness equation formSU <- NULL # inefficiency equation (unused ) m1 <- snsf( formula = spe.tl, data = banks07, prod = myprod, ln.var.v = formSV, skew.v = formSK ) coef(m1)","code":""},{"path":[]},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"id_--5","dir":"","previous_headings":"","what":"â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”-","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"formSV <- ~ log(TA) # heteroskedastic variance formSK <- ~ ER # skewness driver formSU <- ~ LA + ER # inefficiency m2 <- snsf( formula = spe.tl, data = banks07, prod = myprod, ln.var.v = formSV, skew.v = formSK ) coef(m2) ```","code":""},{"path":"https://olegbadunenko.github.io/snreg/README_old.html","id":"additional-resources","dir":"","previous_headings":"","what":"Additional Resources","title":"ðŸ“¦ Installing snreg R Package from GitHub","text":"added","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/articles/illustration.html","id":"data","dir":"Articles","previous_headings":"Illustration","what":"Data","title":"Illustration","text":"data frame containing selected variables 500 U.S. commercial banks, randomly sampled approximately 5000 banks, based dataset Koetter et al.Â (2012) year 2007. dataset provided solely illustration pedagogical purposes suitable empirical research.","code":"library(snreg)   library(tidyverse) #R>  â”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€ #R>  âœ” dplyr     1.1.4     âœ” readr     2.1.6 #R>  âœ” forcats   1.0.1     âœ” stringr   1.6.0 #R>  âœ” ggplot2   4.0.1     âœ” tibble    3.3.0 #R>  âœ” lubridate 1.9.4     âœ” tidyr     1.3.1 #R>  âœ” purrr     1.2.0      #R>  â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€ #R>  âœ– dplyr::filter() masks stats::filter() #R>  âœ– dplyr::lag()    masks stats::lag() #R>  â„¹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors   data(banks07, package = \"snreg\")   head(banks07) #R>        id year        TC       Y1        Y2       W1       W2       W3        ER #R>  1 152440 2007  4659.505  8661.84  58393.04 38.55422 37.75000 4.146092 0.1117789 #R>  2 544335 2007 10848.960 19492.91 146789.00 30.66785 45.13934 2.263886 0.1139121 #R>  3 548203 2007 14523.650 18630.49 219705.70 27.38797 56.02857 4.312672 0.1342984 #R>  4 568238 2007  1644.808 11902.50  18675.68 32.84768 50.47368 1.541316 0.1029891 #R>  5 651158 2007  3054.240 29322.21  38916.14 42.20033 52.23529 3.192056 0.1421004 #R>  6 705444 2007  6168.736 36568.03  67179.16 11.95771 41.46667 3.181241 0.1449880 #R>           LA        TA    ZSCORE  ZSCORE3     SDROA       LLP lnzscore lnzscore3 #R>  1 0.7781611  75039.78  29.49198 11.93898 0.4532092  732.4904 3.384118  2.479809 #R>  2 0.7679300 191148.92  62.97659 20.66493 0.2298561  305.9889 4.142763  3.028438 #R>  3 0.8880010 247416.05  38.99969 30.88642 0.3874364 1534.6521 3.663554  3.430317 #R>  4 0.5050412  36978.53  30.68124 24.53655 0.4063778    0.0000 3.423651  3.200164 #R>  5 0.5264002  73928.81  30.02672 28.42257 0.5496323    0.0000 3.402088  3.347184 #R>  6 0.5222276 128639.62 110.67650 37.66002 0.1502981    0.0000 4.706612  3.628599 #R>       lnsdroa     scope ms_county #R>  1 -0.7914014 0.4801792 0.3466652 #R>  2 -1.4703018 0.5254947 0.8830606 #R>  3 -0.9482036 0.8897177 1.1430008 #R>  4 -0.9004720 0.3917692 0.1708316 #R>  5 -0.5985058 0.5523984 0.3415328 #R>  6 -1.8951346 0.4073012 0.5942832"},{"path":"https://olegbadunenko.github.io/snreg/articles/illustration.html","id":"specification","dir":"Articles","previous_headings":"Illustration","what":"Specification","title":"Illustration","text":"Define specification (formula) used:","code":"# Translog cost function specification spe.tl <- log(TC) ~ (log(Y1) + log(Y2) + log(W1) + log(W2))^2 +   I(0.5 * log(Y1)^2) + I(0.5 * log(Y2)^2) +   I(0.5 * log(W1)^2) + I(0.5 * log(W2)^2)"},{"path":"https://olegbadunenko.github.io/snreg/articles/illustration.html","id":"linear-regression-via-mle","dir":"Articles","previous_headings":"Illustration","what":"Linear Regression via MLE","title":"Illustration","text":"estimate simple OLS using MLE","code":"# ------------------------------------------------------------- # Specification 1: homoskedastic noise (ln.var.v = NULL) # ------------------------------------------------------------- formSV <- NULL  m1 <- lm.mle(   formula   = spe.tl,   data      = banks07,   ln.var.v  = formSV ) #R>   theta0: #R>           (Intercept)              log(Y1)              log(Y2)  #R>          -4.386991731          0.415874408          0.370050861  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>           0.524152369          1.342097991          0.047454756  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>           0.077484315          0.034996665         -0.226281101  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>          -0.057609631         -0.020462972         -0.005676474  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>           0.013639077          0.018840745         -0.154925076  #R>  lnVARv0i_(Intercept)  #R>          -3.687587268  #R>   #R>  -------------- Regression with normal errors: --------------- #R>   #R>  initial  value -212.427550  #R>  iter   1 value -212.427550 #R>  final  value -212.427550  #R>  converged #R>                         Estimate    Std.Err  Z value    Pr(>z)     #R>  (Intercept)          -4.3869917  3.0631686  -1.4322 0.1520939     #R>  log(Y1)               0.4158744  0.1494204   2.7832 0.0053817 **  #R>  log(Y2)               0.3700509  0.2827874   1.3086 0.1906756     #R>  log(W1)               0.5241524  0.2828127   1.8534 0.0638314 .   #R>  log(W2)               1.3420980  1.2504546   1.0733 0.2831419     #R>  I(0.5 * log(Y1)^2)    0.0474548  0.0060002   7.9088 2.665e-15 *** #R>  I(0.5 * log(Y2)^2)    0.0774843  0.0225416   3.4374 0.0005873 *** #R>  I(0.5 * log(W1)^2)    0.0349967  0.0273035   1.2818 0.1999249     #R>  I(0.5 * log(W2)^2)   -0.2262811  0.3426730  -0.6603 0.5090349     #R>  log(Y1):log(Y2)      -0.0576096  0.0113060  -5.0955 3.479e-07 *** #R>  log(Y1):log(W1)      -0.0204630  0.0121495  -1.6843 0.0921316 .   #R>  log(Y1):log(W2)      -0.0056765  0.0386938  -0.1467 0.8833669     #R>  log(Y2):log(W1)       0.0136391  0.0161416   0.8450 0.3981301     #R>  log(Y2):log(W2)       0.0188407  0.0596386   0.3159 0.7520666     #R>  log(W1):log(W2)      -0.1549251  0.0695098  -2.2288 0.0258257 *   #R>  lnVARv0i_(Intercept) -3.6875873  0.0632455 -58.3059 < 2.2e-16 *** #R>  --- #R>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #R>  _____________________________________________________________  coef(m1) #R>           (Intercept)              log(Y1)              log(Y2)  #R>          -4.386991731          0.415874408          0.370050861  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>           0.524152369          1.342097991          0.047454756  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>           0.077484315          0.034996665         -0.226281101  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>          -0.057609631         -0.020462972         -0.005676474  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>           0.013639077          0.018840745         -0.154925076  #R>  lnVARv0i_(Intercept)  #R>          -3.687587268   # ------------------------------------------------------------- # Specification 2: heteroskedastic noise (variance depends on TA) # ------------------------------------------------------------- formSV <- ~ log(TA)  m2 <- lm.mle(   formula   = spe.tl,   data      = banks07,   ln.var.v  = formSV ) #R>   theta0: #R>           (Intercept)              log(Y1)              log(Y2)  #R>          -4.386991731          0.415874408          0.370050861  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>           0.524152369          1.342097991          0.047454756  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>           0.077484315          0.034996665         -0.226281101  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>          -0.057609631         -0.020462972         -0.005676474  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>           0.013639077          0.018840745         -0.154925076  #R>  lnVARv0i_(Intercept)     lnVARv0i_log(TA)  #R>          -3.687587268          0.000000000  #R>   #R>  -------------- Regression with normal errors: --------------- #R>   #R>  initial  value -212.427550  #R>  iter   2 value -212.435637 #R>  iter   2 value -212.435637 #R>  iter   2 value -212.435638 #R>  final  value -212.435638  #R>  converged #R>                          Estimate     Std.Err Z value    Pr(>z)     #R>  (Intercept)          -4.38699173  3.07286157 -1.4277 0.1533907     #R>  log(Y1)               0.41587442  0.14997873  2.7729 0.0055561 **  #R>  log(Y2)               0.37005087  0.29216784  1.2666 0.2053093     #R>  log(W1)               0.52415237  0.28241172  1.8560 0.0634555 .   #R>  log(W2)               1.34209799  1.25258014  1.0715 0.2839596     #R>  I(0.5 * log(Y1)^2)    0.04745481  0.00604526  7.8499 4.219e-15 *** #R>  I(0.5 * log(Y2)^2)    0.07748436  0.02254101  3.4375 0.0005871 *** #R>  I(0.5 * log(W1)^2)    0.03499667  0.02724489  1.2845 0.1989592     #R>  I(0.5 * log(W2)^2)   -0.22628109  0.34575683 -0.6545 0.5128209     #R>  log(Y1):log(Y2)      -0.05760953  0.01151446 -5.0032 5.638e-07 *** #R>  log(Y1):log(W1)      -0.02046294  0.01213895 -1.6857 0.0918485 .   #R>  log(Y1):log(W2)      -0.00567644  0.03861266 -0.1470 0.8831243     #R>  log(Y2):log(W1)       0.01363911  0.01617084  0.8434 0.3989832     #R>  log(Y2):log(W2)       0.01884078  0.06006921  0.3137 0.7537860     #R>  log(W1):log(W2)      -0.15492507  0.06936169 -2.2336 0.0255105 *   #R>  lnVARv0i_(Intercept) -3.68758724  1.00965557 -3.6523 0.0002599 *** #R>  lnVARv0i_log(TA)     -0.00036448  0.08630781 -0.0042 0.9966305     #R>  --- #R>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #R>  _____________________________________________________________  coef(m2) #R>           (Intercept)              log(Y1)              log(Y2)  #R>         -4.3869917305         0.4158744170         0.3700508703  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>          0.5241523719         1.3420979943         0.0474548059  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>          0.0774843635         0.0349966695        -0.2262810941  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>         -0.0576095323        -0.0204629424        -0.0056764377  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>          0.0136391061         0.0188407818        -0.1549250651  #R>  lnVARv0i_(Intercept)     lnVARv0i_log(TA)  #R>         -3.6875872440        -0.0003644791"},{"path":"https://olegbadunenko.github.io/snreg/articles/illustration.html","id":"linear-regression-with-skew-normal-errors","dir":"Articles","previous_headings":"Illustration","what":"Linear Regression with Skew-Normal Errors","title":"Illustration","text":"snreg fits linear regression model disturbance term follows skew-normal distribution.","code":"# ------------------------------------------------------------- # Specification 1: homoskedastic & symmetric noise # ------------------------------------------------------------- formSV <- NULL     # variance equation formSK <- NULL     # skewness equation  m1 <- snreg(   formula  = spe.tl,   data     = banks07,   ln.var.v = formSV,   skew.v   = formSK ) #R>   theta0: #R>           (Intercept)              log(Y1)              log(Y2)  #R>          -4.386991731          0.415874408          0.370050861  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>           0.524152369          1.342097991          0.047454756  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>           0.077484315          0.034996665         -0.226281101  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>          -0.057609631         -0.020462972         -0.005676474  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>           0.013639077          0.018840745         -0.154925076  #R>  lnVARv0i_(Intercept) Skew_v0i_(Intercept)  #R>          -3.687587268          3.000000000  #R>   #R>  -------------- Regression with skewed errors: --------------- #R>   #R>  Iteration   0 (at starting values):       log likelihood = 5.146960520337 #R>   #R>  Iteration   1 (hessian is provided,   1 in total):   log likelihood = 201.5619797261 #R>  Iteration   2 (hessian is provided,   2 in total):   log likelihood = 218.5157385369 #R>  Iteration   3 (hessian is provided,   3 in total):   log likelihood = 219.8304053615 #R>  Iteration   4 (hessian is provided,   4 in total):   log likelihood = 221.1570395072 #R>  Iteration   5 (hessian is provided,   5 in total):   log likelihood = 221.4173977326 #R>  Iteration   6 (hessian is provided,   6 in total):   log likelihood = 221.45910305 #R>  Iteration   7 (hessian is provided,   7 in total):   log likelihood = 221.4742381631 #R>  Iteration   8 (hessian is provided,   8 in total):   log likelihood = 221.4742892007 #R>  Iteration   9 (hessian is provided,   9 in total):   log likelihood = 221.4772909678 #R>   #R>  Convergence given g inv(H) g' = 1.147956e-05 < lmtol #R>   #R>  Final log likelihood = 221.4772909678 #R>   #R>                          Estimate     Std.Err  Z value    Pr(>z)     #R>  (Intercept)          -5.88439482  3.00884171  -1.9557  0.050500 .   #R>  log(Y1)               0.43986913  0.15724371   2.7974  0.005152 **  #R>  log(Y2)               0.50497847  0.27574767   1.8313  0.067055 .   #R>  log(W1)               0.54680112  0.27757332   1.9699  0.048846 *   #R>  log(W2)               1.62221319  1.19336826   1.3594  0.174034     #R>  I(0.5 * log(Y1)^2)    0.04152960  0.00579831   7.1624 7.929e-13 *** #R>  I(0.5 * log(Y2)^2)    0.06775246  0.02251267   3.0095  0.002617 **  #R>  I(0.5 * log(W1)^2)    0.03985513  0.02624261   1.5187  0.128833     #R>  I(0.5 * log(W2)^2)   -0.28421570  0.32037935  -0.8871  0.375013     #R>  log(Y1):log(Y2)      -0.05595449  0.01162258  -4.8143 1.477e-06 *** #R>  log(Y1):log(W1)      -0.02195339  0.01251279  -1.7545  0.079349 .   #R>  log(Y1):log(W2)       0.00032291  0.04106930   0.0079  0.993727     #R>  log(Y2):log(W1)       0.01294569  0.01577160   0.8208  0.411747     #R>  log(Y2):log(W2)       0.00975499  0.05798118   0.1682  0.866391     #R>  log(W1):log(W2)      -0.15803381  0.06620501  -2.3870  0.016985 *   #R>  lnVARv0i_(Intercept) -3.01076847  0.11366937 -26.4871 < 2.2e-16 *** #R>  Skew_v0i_(Intercept)  1.86603587  0.32264117   5.7836 7.311e-09 *** #R>  --- #R>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #R>  _____________________________________________________________  coef(m1) #R>           (Intercept)              log(Y1)              log(Y2)  #R>          -5.884394817          0.439869125          0.504978469  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>           0.546801118          1.622213193          0.041529597  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>           0.067752458          0.039855132         -0.284215702  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>          -0.055954492         -0.021953387          0.000322907  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>           0.012945689          0.009754988         -0.158033814  #R>  lnVARv0i_(Intercept) Skew_v0i_(Intercept)  #R>          -3.010768472          1.866035868   # ------------------------------------------------------------- # Specification 2: heteroskedastic + skewed noise # ------------------------------------------------------------- formSV <- ~ log(TA)   # heteroskedasticity in v formSK <- ~ ER        # skewness driven by equity ratio  m2 <- snreg(   formula  = spe.tl,   data     = banks07,   ln.var.v = formSV,   skew.v   = formSK ) #R>   theta0: #R>                (Intercept)                   log(Y1)                   log(Y2)  #R>               -4.386991731               0.415874408               0.370050861  #R>                    log(W1)                   log(W2)        I(0.5 * log(Y1)^2)  #R>                0.524152369               1.342097991               0.047454756  #R>         I(0.5 * log(Y2)^2)        I(0.5 * log(W1)^2)        I(0.5 * log(W2)^2)  #R>                0.077484315               0.034996665              -0.226281101  #R>            log(Y1):log(Y2)           log(Y1):log(W1)           log(Y1):log(W2)  #R>               -0.057609631              -0.020462972              -0.005676474  #R>            log(Y2):log(W1)           log(Y2):log(W2)           log(W1):log(W2)  #R>                0.013639077               0.018840745              -0.154925076  #R>       lnVARv0i_(Intercept) lnVARv0i_lnVARv0i_log(TA)      Skew_v0i_(Intercept)  #R>               -3.687587268               0.000000000               3.000000000  #R>       Skew_v0i_Skew_v0i_ER  #R>                0.000000000  #R>   #R>  ----------------- Regression with skewed errors: ----------------- #R>   #R>  Iteration   0 (at starting values):       log likelihood = 5.146960520337 #R>   #R>  Iteration   1 (hessian is provided,   1 in total):   log likelihood = 204.6988401214 #R>  Iteration   2 (hessian is provided,   2 in total):   log likelihood = 221.6390613234 #R>  Iteration   3 (hessian is provided,   3 in total):   log likelihood = 224.8771023643 #R>  Iteration   4 (hessian is provided,   4 in total):   log likelihood = 225.6867346145 #R>  Iteration   5 (hessian is provided,   5 in total):   log likelihood = 225.9380532273 #R>  Iteration   6 (hessian is provided,   6 in total):   log likelihood = 226.0484166119 #R>  Iteration   7 (hessian is provided,   7 in total):   log likelihood = 226.0721225638 #R>  Iteration   8 (hessian is provided,   8 in total):   log likelihood = 226.0820635056 #R>  Iteration   9 (hessian is provided,   9 in total):   log likelihood = 226.0835072457 #R>  Iteration  10 (hessian is provided,  10 in total):   log likelihood = 226.0909506421 #R>   #R>  Convergence given g inv(H) g' = 9.357213e-05 < lmtol #R>   #R>  Final log likelihood = 226.0909506421 #R>   #R>                               Estimate     Std.Err Z value    Pr(>z)     #R>  (Intercept)               -5.71501334  2.98991742 -1.9114  0.055950 .   #R>  log(Y1)                    0.45216186  0.15708195  2.8785  0.003996 **  #R>  log(Y2)                    0.64671047  0.28153250  2.2971  0.021613 *   #R>  log(W1)                    0.48917765  0.27664356  1.7683  0.077018 .   #R>  log(W2)                    1.15530138  1.17400483  0.9841  0.325082     #R>  I(0.5 * log(Y1)^2)         0.04070906  0.00590546  6.8935 5.445e-12 *** #R>  I(0.5 * log(Y2)^2)         0.06170967  0.02265802  2.7235  0.006459 **  #R>  I(0.5 * log(W1)^2)         0.04271441  0.02667730  1.6012  0.109343     #R>  I(0.5 * log(W2)^2)        -0.15999322  0.31994376 -0.5001  0.617028     #R>  log(Y1):log(Y2)           -0.05757860  0.01197968 -4.8064 1.537e-06 *** #R>  log(Y1):log(W1)           -0.01887894  0.01276125 -1.4794  0.139035     #R>  log(Y1):log(W2)            0.00165155  0.04117676  0.0401  0.968006     #R>  log(Y2):log(W1)            0.00516054  0.01583258  0.3259  0.744467     #R>  log(Y2):log(W2)           -0.00022261  0.05922730 -0.0038  0.997001     #R>  log(W1):log(W2)           -0.13107647  0.06626509 -1.9781  0.047922 *   #R>  lnVARv0i_(Intercept)      -0.89452888  1.03829604 -0.8615  0.388943     #R>  lnVARv0i_lnVARv0i_log(TA) -0.17730037  0.08736480 -2.0294  0.042415 *   #R>  Skew_v0i_(Intercept)       3.10567750  0.76059557  4.0832 4.442e-05 *** #R>  Skew_v0i_Skew_v0i_ER      -9.55208958  4.87607389 -1.9590  0.050116 .   #R>  --- #R>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #R>  __________________________________________________________________  coef(m2) #R>                (Intercept)                   log(Y1)                   log(Y2)  #R>              -5.7150133374              0.4521618623              0.6467104718  #R>                    log(W1)                   log(W2)        I(0.5 * log(Y1)^2)  #R>               0.4891776489              1.1553013814              0.0407090640  #R>         I(0.5 * log(Y2)^2)        I(0.5 * log(W1)^2)        I(0.5 * log(W2)^2)  #R>               0.0617096653              0.0427144069             -0.1599932243  #R>            log(Y1):log(Y2)           log(Y1):log(W1)           log(Y1):log(W2)  #R>              -0.0575785975             -0.0188789363              0.0016515541  #R>            log(Y2):log(W1)           log(Y2):log(W2)           log(W1):log(W2)  #R>               0.0051605363             -0.0002226092             -0.1310764688  #R>       lnVARv0i_(Intercept) lnVARv0i_lnVARv0i_log(TA)      Skew_v0i_(Intercept)  #R>              -0.8945288842             -0.1773003673              3.1056774984  #R>       Skew_v0i_Skew_v0i_ER  #R>              -9.5520895773"},{"path":"https://olegbadunenko.github.io/snreg/articles/illustration.html","id":"stochastic-frontier-model-with-a-skew-normally-distributed-error-term","dir":"Articles","previous_headings":"Illustration","what":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term","title":"Illustration","text":"snsf performs maximum likelihood estimation parameters technical cost efficiencies Stochastic Frontier Model skew-normally distributed error term.","code":"myprod <- FALSE  # ------------------------------------------------------------- # Specification 1: homoskedastic & symmetric # ------------------------------------------------------------- formSV <- NULL   # variance equation formSK <- NULL   # skewness equation formSU <- NULL   # inefficiency equation (unused here)  m1 <- snsf(   formula  = spe.tl,   data     = banks07,   prod     = myprod,   ln.var.v = formSV,   skew.v   = formSK ) #R>   #R>  -------------- Regression with skewed errors: --------------- #R>   #R>  initial  value -105.392823  #R>  iter   2 value -105.561746 #R>  iter   3 value -105.568000 #R>  iter   4 value -105.836407 #R>  iter   5 value -106.255928 #R>  iter   6 value -107.989401 #R>  iter   7 value -129.390401 #R>  iter   8 value -148.614164 #R>  iter   8 value -148.614164 #R>  iter   9 value -148.627674 #R>  iter  10 value -148.628304 #R>  iter  10 value -148.628304 #R>  iter  10 value -148.628304 #R>  final  value -148.628304  #R>  converged #R>                          Estimate     Std.Err  Z value    Pr(>z)     #R>  X(Intercept)         -4.40500089  3.80254827  -1.1584  0.246687     #R>  Xlog(Y1)              0.45706967  0.18307828   2.4966  0.012540 *   #R>  Xlog(Y2)              0.31560584  0.33532057   0.9412  0.346599     #R>  Xlog(W1)              0.48827077  0.38637994   1.2637  0.206335     #R>  Xlog(W2)              1.29215252  1.70829901   0.7564  0.449411     #R>  XI(0.5 * log(Y1)^2)   0.06252731  0.00718640   8.7008 < 2.2e-16 *** #R>  XI(0.5 * log(Y2)^2)   0.19680294  0.03130033   6.2876 3.225e-10 *** #R>  XI(0.5 * log(W1)^2)   0.05041646  0.03723206   1.3541  0.175700     #R>  XI(0.5 * log(W2)^2)  -0.28522159  0.46697561  -0.6108  0.541342     #R>  Xlog(Y1):log(Y2)     -0.14258698  0.00610987 -23.3372 < 2.2e-16 *** #R>  Xlog(Y1):log(W1)      0.00029592  0.01705705   0.0173  0.986158     #R>  Xlog(Y1):log(W2)      0.17610934  0.05558196   3.1685  0.001532 **  #R>  Xlog(Y2):log(W1)      0.01454480  0.02162340   0.6726  0.501175     #R>  Xlog(Y2):log(W2)     -0.09354141  0.07710129  -1.2132  0.225043     #R>  Xlog(W1):log(W2)     -0.21197450  0.09475124  -2.2372  0.025275 *   #R>  lnVARv0i_(Intercept) -2.66540968  0.11013951 -24.2003 < 2.2e-16 *** #R>  Skew_v0i_(Intercept)  0.98854923  0.03434255  28.7850 < 2.2e-16 *** #R>  sv                    0.26376286  0.00766250  34.4226 < 2.2e-16 *** #R>  --- #R>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #R>  _____________________________________________________________ #R>   theta0: #R>           (Intercept)              log(Y1)              log(Y2)  #R>         -4.4050008900         0.4570696682         0.3156058426  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>          0.4882707672         1.2921525200         0.0625273146  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>          0.1968029394         0.0504164557        -0.2852215911  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>         -0.1425869800         0.0002959179         0.1761093362  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>          0.0145448021        -0.0935414140        -0.2119744969  #R>  lnVARv0i_(Intercept) Skew_v0i_(Intercept) lnVARu0i_(Intercept)  #R>         -4.2020745955         0.3982617494        -4.5984104618  #R>   #R>  ---------------------- The main model: ---------------------- #R>   #R>  Iteration   0 (at starting values):       log likelihood = 21.64346032248 #R>   #R>  Iteration   1 (hessian is provided,   1 in total):   log likelihood = 186.4880063145 #R>  Iteration   2 (hessian is provided,   2 in total):   log likelihood = 214.3430643968 #R>  Iteration   3 (hessian is provided,   3 in total):   log likelihood = 220.957921695 #R>  Iteration   4 (hessian is provided,   4 in total):   log likelihood = 223.1040419712 #R>  Iteration   5 (hessian is provided,   5 in total):   log likelihood = 224.3725358921 #R>  Iteration   6 (hessian is provided,   6 in total):   log likelihood = 224.6133195507 #R>  Iteration   7 (hessian is provided,   7 in total):   log likelihood = 224.7096271178 #R>  Iteration   8 (hessian is provided,   8 in total):   log likelihood = 224.7298349674 #R>  Iteration   9 (hessian is provided,   9 in total):   log likelihood = 224.8005650898 #R>  Iteration  10 (hessian is provided,  10 in total):   log likelihood = 224.8011109934 #R>  Iteration  11 (hessian is provided,  11 in total):   log likelihood = 224.8019248405 #R>  Iteration  12 (hessian is provided,  12 in total):   log likelihood = 224.8021079368 #R>  Iteration  13 (hessian is provided,  13 in total):   log likelihood = 224.8054321542 #R>  Iteration  14 (hessian is provided,  14 in total):   log likelihood = 224.8420044777 #R>  Iteration  15 (hessian is provided,  15 in total):   log likelihood = 225.4135588864 #R>  Iteration  16 (hessian is provided,  16 in total):   log likelihood = 225.5282232035 #R>  Iteration  17 (hessian is provided,  17 in total):   log likelihood = 225.533351752 #R>  Iteration  18 (hessian is provided,  18 in total):   log likelihood = 225.5368333384 #R>  Iteration  19 (hessian is provided,  19 in total):   log likelihood = 225.5371105355 #R>  Iteration  20 (hessian is provided,  20 in total):   log likelihood = 225.539300346 #R>  Iteration  21 (hessian is provided,  21 in total):   log likelihood = 225.539317247 #R>  Iteration  22 (hessian is provided,  22 in total):   log likelihood = 225.539324279 #R>   #R>  Convergence given g inv(H) g' = 1.027857e-06 < lmtol #R>   #R>  Final log likelihood = 225.539324279 #R>   #R>   #R>  Log likelihood maximization completed in #R>  0.18 seconds #R>  _____________________________________________________________ #R>   #R>  Cross-sectional stochastic (cost) frontier model #R>   #R>  Distributional assumptions #R>   #R>    Component      Distribution Assumption    #R>  1 Random noise:  skew normal  homoskedastic #R>  2 Inefficiency:  exponential  homoskedastic #R>   #R>  Number of observations = 500 #R>   #R>  -------------------- Estimation results: -------------------- #R>   #R>                            Coef.        SE       z       P>|z| #R>  _____________________________________________________________ #R>  Frontier #R>                                                                    #R>  (Intercept)             -6.3606     3.0602   -2.08     0.0377 *   #R>  log(Y1)                  0.4425     0.1767    2.50     0.0123 *   #R>  log(Y2)                  0.5660     0.2753    2.06     0.0398 *   #R>  log(W1)                  0.4983     0.2835    1.76     0.0788 .   #R>  log(W2)                  1.6557     1.1889    1.39     0.1637     #R>  I(0.5 * log(Y1)^2)       0.0449     0.0066    6.76     0.0000 *** #R>  I(0.5 * log(Y2)^2)       0.0650     0.0222    2.93     0.0034 **  #R>  I(0.5 * log(W1)^2)       0.0363     0.0258    1.41     0.1597     #R>  I(0.5 * log(W2)^2)      -0.3099     0.3170   -0.98     0.3283     #R>  log(Y1):log(Y2)         -0.0586     0.0117   -4.99     0.0000 *** #R>  log(Y1):log(W1)         -0.0227     0.0127   -1.78     0.0750 .   #R>  log(Y1):log(W2)         -0.0006     0.0420   -0.01     0.9895     #R>  log(Y2):log(W1)          0.0117     0.0152    0.77     0.4393     #R>  log(Y2):log(W2)          0.0106     0.0563    0.19     0.8505     #R>  log(W1):log(W2)         -0.1375     0.0682   -2.02     0.0438 *   #R>  ------------------------------------------------------------- #R>  Variance of the random noise component: log(sigma_v^2) #R>                                                                    #R>  lnVARv0i_(Intercept)    -3.8207     0.2255  -16.94     0.0000 *** #R>  ------------------------------------------------------------- #R>  Skewness of the random noise component: `alpha` #R>                                                                    #R>  Skew_v0i_(Intercept)    -1.5007     0.8755   -1.71     0.0865 .   #R>  ------------------------------------------------------------- #R>  Inefficiency component: log(sigma_u^2) #R>                                                                    #R>  lnVARu0i_(Intercept)    -4.3422     0.2398  -18.11     0.0000 *** #R>  _____________________________________________________________ #R>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #R>   #R>  --------------- Summary of cost efficiencies: --------------- #R>   #R>                  JLMS:= exp(-E[ui|ei]) #R>   #R>        TE_JLMS #R>  Obs       500 #R>  NAs         0 #R>  Mean   0.8955 #R>  StDev  0.0715 #R>  IQR    0.0645 #R>  Min    0.4559 #R>  5%     0.7420 #R>  10%    0.7959 #R>  25%    0.8780 #R>  50%    0.9208 #R>  75%    0.9425 #R>  90%    0.9520 #R>  Max    0.9691  coef(m1) #R>           (Intercept)              log(Y1)              log(Y2)  #R>         -6.3606134654         0.4425312174         0.5660453675  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>          0.4983319531         1.6557355502         0.0448519992  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>          0.0649995029         0.0362747554        -0.3099280819  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>         -0.0586056701        -0.0226917826        -0.0005509121  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>          0.0117430476         0.0106095399        -0.1375404433  #R>  lnVARv0i_(Intercept) Skew_v0i_(Intercept) lnVARu0i_(Intercept)  #R>         -3.8206601915        -1.5006628040        -4.3422317628   # ------------------------------------------------------------- # Specification 2: heteroskedastic + skewed noise # ------------------------------------------------------------- formSV <- ~ log(TA)      # heteroskedastic variance formSK <- ~ ER           # skewness driver formSU <- ~ LA + ER      # inefficiency  m2 <- snsf(   formula  = spe.tl,   data     = banks07,   prod     = myprod,   ln.var.v = formSV,   skew.v   = formSK ) #R>   #R>  -------------- Regression with skewed errors: --------------- #R>   #R>  initial  value -105.392823  #R>  iter   2 value -105.561746 #R>  iter   3 value -105.568000 #R>  iter   4 value -105.836407 #R>  iter   5 value -106.255928 #R>  iter   6 value -107.989401 #R>  iter   7 value -129.390401 #R>  iter   8 value -148.614164 #R>  iter   8 value -148.614164 #R>  iter   9 value -148.627674 #R>  iter  10 value -148.628304 #R>  iter  10 value -148.628304 #R>  iter  10 value -148.628304 #R>  final  value -148.628304  #R>  converged #R>                          Estimate     Std.Err  Z value    Pr(>z)     #R>  X(Intercept)         -4.40500089  3.80254827  -1.1584  0.246687     #R>  Xlog(Y1)              0.45706967  0.18307828   2.4966  0.012540 *   #R>  Xlog(Y2)              0.31560584  0.33532057   0.9412  0.346599     #R>  Xlog(W1)              0.48827077  0.38637994   1.2637  0.206335     #R>  Xlog(W2)              1.29215252  1.70829901   0.7564  0.449411     #R>  XI(0.5 * log(Y1)^2)   0.06252731  0.00718640   8.7008 < 2.2e-16 *** #R>  XI(0.5 * log(Y2)^2)   0.19680294  0.03130033   6.2876 3.225e-10 *** #R>  XI(0.5 * log(W1)^2)   0.05041646  0.03723206   1.3541  0.175700     #R>  XI(0.5 * log(W2)^2)  -0.28522159  0.46697561  -0.6108  0.541342     #R>  Xlog(Y1):log(Y2)     -0.14258698  0.00610987 -23.3372 < 2.2e-16 *** #R>  Xlog(Y1):log(W1)      0.00029592  0.01705705   0.0173  0.986158     #R>  Xlog(Y1):log(W2)      0.17610934  0.05558196   3.1685  0.001532 **  #R>  Xlog(Y2):log(W1)      0.01454480  0.02162340   0.6726  0.501175     #R>  Xlog(Y2):log(W2)     -0.09354141  0.07710129  -1.2132  0.225043     #R>  Xlog(W1):log(W2)     -0.21197450  0.09475124  -2.2372  0.025275 *   #R>  lnVARv0i_(Intercept) -2.66540968  0.11013951 -24.2003 < 2.2e-16 *** #R>  Skew_v0i_(Intercept)  0.98854923  0.03434255  28.7850 < 2.2e-16 *** #R>  sv                    0.26376286  0.00766250  34.4226 < 2.2e-16 *** #R>  --- #R>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #R>  _____________________________________________________________ #R>   theta0: #R>           (Intercept)              log(Y1)              log(Y2)  #R>         -4.405001e+00         4.570697e-01         3.156058e-01  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>          4.882708e-01         1.292153e+00         6.252731e-02  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>          1.968029e-01         5.041646e-02        -2.852216e-01  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>         -1.425870e-01         2.959179e-04         1.761093e-01  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>          1.454480e-02        -9.354141e-02        -2.119745e-01  #R>  lnVARv0i_(Intercept)     lnVARv0i_log(TA) Skew_v0i_(Intercept)  #R>         -4.202075e+00         2.212626e-16         3.982617e-01  #R>           Skew_v0i_ER lnVARu0i_(Intercept)  #R>          0.000000e+00        -4.598410e+00  #R>   #R>  ---------------------- The main model: ---------------------- #R>   #R>  Iteration   0 (at starting values):       log likelihood = 21.64346032248 #R>   #R>  Iteration   1 (hessian is provided,   1 in total):   log likelihood = 133.2018982456 #R>  Iteration   2 (hessian is provided,   2 in total):   log likelihood = 183.2824024606 #R>  Iteration   3 (hessian is provided,   3 in total):   log likelihood = 214.7412845581 #R>  Iteration   4 (hessian is provided,   4 in total):   log likelihood = 223.1763227676 #R>  Iteration   5 (hessian is provided,   5 in total):   log likelihood = 226.655477596 #R>  Iteration   6 (hessian is provided,   6 in total):   log likelihood = 226.7105002202 #R>  Iteration   7 (hessian is provided,   7 in total):   log likelihood = 226.8074129256 #R>  Iteration   8 (hessian is provided,   8 in total):   log likelihood = 226.8082101988 #R>  Iteration   9 (hessian is provided,   9 in total):   log likelihood = 226.8082151929 #R>  Iteration  10 (hessian is provided,  10 in total):   log likelihood = 226.808224564 #R>   #R>  Convergence given g inv(H) g' = 2.529443e-06 < lmtol #R>   #R>  Final log likelihood = 226.808224564 #R>   #R>   #R>  Log likelihood maximization completed in #R>  0.103 seconds #R>  _____________________________________________________________ #R>   #R>  Cross-sectional stochastic (cost) frontier model #R>   #R>  Distributional assumptions #R>   #R>    Component      Distribution Assumption      #R>  1 Random noise:  skew normal  heteroskedastic #R>  2 Inefficiency:  exponential  homoskedastic   #R>   #R>  Number of observations = 500 #R>   #R>  -------------------- Estimation results: -------------------- #R>   #R>                            Coef.        SE       z       P>|z| #R>  _____________________________________________________________ #R>  Frontier #R>                                                                    #R>  (Intercept)             -5.9441     3.0205   -1.97     0.0491 *   #R>  log(Y1)                  0.4589     0.1647    2.79     0.0053 **  #R>  log(Y2)                  0.6135     0.2820    2.18     0.0296 *   #R>  log(W1)                  0.5168     0.2747    1.88     0.0599 .   #R>  log(W2)                  1.2707     1.1934    1.06     0.2870     #R>  I(0.5 * log(Y1)^2)       0.0414     0.0061    6.81     0.0000 *** #R>  I(0.5 * log(Y2)^2)       0.0614     0.0226    2.72     0.0065 **  #R>  I(0.5 * log(W1)^2)       0.0439     0.0262    1.68     0.0938 .   #R>  I(0.5 * log(W2)^2)      -0.2078     0.3247   -0.64     0.5223     #R>  log(Y1):log(Y2)         -0.0575     0.0120   -4.79     0.0000 *** #R>  log(Y1):log(W1)         -0.0215     0.0128   -1.68     0.0927 .   #R>  log(Y1):log(W2)          0.0000     0.0417    0.00     0.9997     #R>  log(Y2):log(W1)          0.0068     0.0158    0.43     0.6682     #R>  log(Y2):log(W2)          0.0086     0.0589    0.15     0.8836     #R>  log(W1):log(W2)         -0.1368     0.0661   -2.07     0.0384 *   #R>  ------------------------------------------------------------- #R>  Variance of the random noise component: log(sigma_v^2) #R>                                                                    #R>  lnVARv0i_(Intercept)    -1.8839     1.6595   -1.14     0.2563     #R>  lnVARv0i_log(TA)        -0.1558     0.1328   -1.17     0.2407     #R>  ------------------------------------------------------------- #R>  Skewness of the random noise component: `alpha` #R>                                                                    #R>  Skew_v0i_(Intercept)     2.0043     1.0468    1.91     0.0555 .   #R>  Skew_v0i_ER             -7.2632     5.0581   -1.44     0.1510     #R>  ------------------------------------------------------------- #R>  Inefficiency component: log(sigma_u^2) #R>                                                                    #R>  lnVARu0i_(Intercept)    -4.6407     0.3416  -13.58     0.0000 *** #R>  _____________________________________________________________ #R>  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #R>   #R>  --------------- Summary of cost efficiencies: --------------- #R>   #R>                  JLMS:= exp(-E[ui|ei]) #R>   #R>        TE_JLMS #R>  Obs       500 #R>  NAs         0 #R>  Mean   0.9084 #R>  StDev  0.0564 #R>  IQR    0.0547 #R>  Min    0.5206 #R>  5%     0.8096 #R>  10%    0.8379 #R>  25%    0.8903 #R>  50%    0.9241 #R>  75%    0.9450 #R>  90%    0.9568 #R>  Max    0.9758  coef(m2) #R>           (Intercept)              log(Y1)              log(Y2)  #R>         -5.944090e+00         4.589482e-01         6.134700e-01  #R>               log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #R>          5.167646e-01         1.270694e+00         4.138294e-02  #R>    I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #R>          6.141001e-02         4.385504e-02        -2.077538e-01  #R>       log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #R>         -5.745504e-02        -2.151307e-02         1.351571e-05  #R>       log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #R>          6.752251e-03         8.627646e-03        -1.368348e-01  #R>  lnVARv0i_(Intercept)     lnVARv0i_log(TA) Skew_v0i_(Intercept)  #R>         -1.883867e+00        -1.558322e-01         2.004266e+00  #R>           Skew_v0i_ER lnVARu0i_(Intercept)  #R>         -7.263169e+00        -4.640750e+00"},{"path":"https://olegbadunenko.github.io/snreg/articles/illustration.html","id":"additional-resources","dir":"Articles","previous_headings":"Illustration","what":"Additional Resources","title":"Illustration","text":"See Oleg Badunenko Daniel J. Henderson (2023). â€œProduction analysis asymmetric noiseâ€. Journal Productivity Analysis, 61(1), 1â€“18. DOI details","code":""},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Introduction to snreg","text":"snreg package offers set methods conducting regression analysis model errors follow skew-normal distribution.","code":""},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"framework","dir":"Articles","previous_headings":"Overview","what":"Framework","title":"Introduction to snreg","text":"snreg package implements framework developed : Oleg Badunenko Daniel J. Henderson (2023). â€œProduction analysis asymmetric noiseâ€. Journal Productivity Analysis, 61(1), 1â€“18. DOI","code":""},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Introduction to snreg","text":"illustrate functionality using banks07 dataset, contains selected variables 500 U.S. commercial banks randomly sampled year 2007. Note: dataset provided solely illustration pedagogical purposes suitable empirical research.","code":"data(banks07, package = \"snreg\") head(banks07) #>       id year        TC       Y1        Y2       W1       W2       W3        ER #> 1 152440 2007  4659.505  8661.84  58393.04 38.55422 37.75000 4.146092 0.1117789 #> 2 544335 2007 10848.960 19492.91 146789.00 30.66785 45.13934 2.263886 0.1139121 #> 3 548203 2007 14523.650 18630.49 219705.70 27.38797 56.02857 4.312672 0.1342984 #> 4 568238 2007  1644.808 11902.50  18675.68 32.84768 50.47368 1.541316 0.1029891 #> 5 651158 2007  3054.240 29322.21  38916.14 42.20033 52.23529 3.192056 0.1421004 #> 6 705444 2007  6168.736 36568.03  67179.16 11.95771 41.46667 3.181241 0.1449880 #>          LA        TA    ZSCORE  ZSCORE3     SDROA       LLP lnzscore lnzscore3 #> 1 0.7781611  75039.78  29.49198 11.93898 0.4532092  732.4904 3.384118  2.479809 #> 2 0.7679300 191148.92  62.97659 20.66493 0.2298561  305.9889 4.142763  3.028438 #> 3 0.8880010 247416.05  38.99969 30.88642 0.3874364 1534.6521 3.663554  3.430317 #> 4 0.5050412  36978.53  30.68124 24.53655 0.4063778    0.0000 3.423651  3.200164 #> 5 0.5264002  73928.81  30.02672 28.42257 0.5496323    0.0000 3.402088  3.347184 #> 6 0.5222276 128639.62 110.67650 37.66002 0.1502981    0.0000 4.706612  3.628599 #>      lnsdroa     scope ms_county #> 1 -0.7914014 0.4801792 0.3466652 #> 2 -1.4703018 0.5254947 0.8830606 #> 3 -0.9482036 0.8897177 1.1430008 #> 4 -0.9004720 0.3917692 0.1708316 #> 5 -0.5985058 0.5523984 0.3415328 #> 6 -1.8951346 0.4073012 0.5942832"},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"model-specification","dir":"Articles","previous_headings":"","what":"Model Specification","title":"Introduction to snreg","text":"Define translog cost function specification:","code":"spe.tl <- log(TC) ~ (log(Y1) + log(Y2) + log(W1) + log(W2))^2 +   I(0.5 * log(Y1)^2) + I(0.5 * log(Y2)^2) +   I(0.5 * log(W1)^2) + I(0.5 * log(W2)^2)"},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"homoskedastic-model","dir":"Articles","previous_headings":"Linear Regression via MLE","what":"Homoskedastic Model","title":"Introduction to snreg","text":"","code":"formSV <- NULL  m1 <- lm.mle(   formula   = spe.tl,   data      = banks07,   ln.var.v  = formSV ) #>  theta0: #>          (Intercept)              log(Y1)              log(Y2)  #>         -4.386991731          0.415874408          0.370050861  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>          0.524152369          1.342097991          0.047454756  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>          0.077484315          0.034996665         -0.226281101  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>         -0.057609631         -0.020462972         -0.005676474  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>          0.013639077          0.018840745         -0.154925076  #> lnVARv0i_(Intercept)  #>         -3.687587268  #>  #> -------------- Regression with normal errors: --------------- #>  #> initial  value -212.427550  #> iter   1 value -212.427550 #> final  value -212.427550  #> converged #>                        Estimate    Std.Err  Z value    Pr(>z)     #> (Intercept)          -4.3869917  3.0631686  -1.4322 0.1520939     #> log(Y1)               0.4158744  0.1494204   2.7832 0.0053817 **  #> log(Y2)               0.3700509  0.2827874   1.3086 0.1906756     #> log(W1)               0.5241524  0.2828127   1.8534 0.0638314 .   #> log(W2)               1.3420980  1.2504546   1.0733 0.2831419     #> I(0.5 * log(Y1)^2)    0.0474548  0.0060002   7.9088 2.665e-15 *** #> I(0.5 * log(Y2)^2)    0.0774843  0.0225416   3.4374 0.0005873 *** #> I(0.5 * log(W1)^2)    0.0349967  0.0273035   1.2818 0.1999249     #> I(0.5 * log(W2)^2)   -0.2262811  0.3426730  -0.6603 0.5090349     #> log(Y1):log(Y2)      -0.0576096  0.0113060  -5.0955 3.479e-07 *** #> log(Y1):log(W1)      -0.0204630  0.0121495  -1.6843 0.0921316 .   #> log(Y1):log(W2)      -0.0056765  0.0386938  -0.1467 0.8833669     #> log(Y2):log(W1)       0.0136391  0.0161416   0.8450 0.3981301     #> log(Y2):log(W2)       0.0188407  0.0596386   0.3159 0.7520666     #> log(W1):log(W2)      -0.1549251  0.0695098  -2.2288 0.0258257 *   #> lnVARv0i_(Intercept) -3.6875873  0.0632455 -58.3059 < 2.2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> _____________________________________________________________  coef(m1) #>          (Intercept)              log(Y1)              log(Y2)  #>         -4.386991731          0.415874408          0.370050861  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>          0.524152369          1.342097991          0.047454756  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>          0.077484315          0.034996665         -0.226281101  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>         -0.057609631         -0.020462972         -0.005676474  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>          0.013639077          0.018840745         -0.154925076  #> lnVARv0i_(Intercept)  #>         -3.687587268"},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"heteroskedastic-model","dir":"Articles","previous_headings":"Linear Regression via MLE","what":"Heteroskedastic Model","title":"Introduction to snreg","text":"Variance depends total assets (TA):","code":"formSV <- ~ log(TA)  m2 <- lm.mle(   formula   = spe.tl,   data      = banks07,   ln.var.v  = formSV ) #>  theta0: #>          (Intercept)              log(Y1)              log(Y2)  #>         -4.386991731          0.415874408          0.370050861  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>          0.524152369          1.342097991          0.047454756  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>          0.077484315          0.034996665         -0.226281101  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>         -0.057609631         -0.020462972         -0.005676474  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>          0.013639077          0.018840745         -0.154925076  #> lnVARv0i_(Intercept)     lnVARv0i_log(TA)  #>         -3.687587268          0.000000000  #>  #> -------------- Regression with normal errors: --------------- #>  #> initial  value -212.427550  #> iter   2 value -212.435637 #> iter   2 value -212.435637 #> iter   2 value -212.435638 #> final  value -212.435638  #> converged #>                         Estimate     Std.Err Z value    Pr(>z)     #> (Intercept)          -4.38699173  3.07286157 -1.4277 0.1533907     #> log(Y1)               0.41587442  0.14997873  2.7729 0.0055561 **  #> log(Y2)               0.37005087  0.29216784  1.2666 0.2053093     #> log(W1)               0.52415237  0.28241172  1.8560 0.0634555 .   #> log(W2)               1.34209799  1.25258014  1.0715 0.2839596     #> I(0.5 * log(Y1)^2)    0.04745481  0.00604526  7.8499 4.219e-15 *** #> I(0.5 * log(Y2)^2)    0.07748436  0.02254101  3.4375 0.0005871 *** #> I(0.5 * log(W1)^2)    0.03499667  0.02724489  1.2845 0.1989592     #> I(0.5 * log(W2)^2)   -0.22628109  0.34575683 -0.6545 0.5128209     #> log(Y1):log(Y2)      -0.05760953  0.01151446 -5.0032 5.638e-07 *** #> log(Y1):log(W1)      -0.02046294  0.01213895 -1.6857 0.0918485 .   #> log(Y1):log(W2)      -0.00567644  0.03861266 -0.1470 0.8831243     #> log(Y2):log(W1)       0.01363911  0.01617084  0.8434 0.3989832     #> log(Y2):log(W2)       0.01884078  0.06006921  0.3137 0.7537860     #> log(W1):log(W2)      -0.15492507  0.06936169 -2.2336 0.0255105 *   #> lnVARv0i_(Intercept) -3.68758724  1.00965557 -3.6523 0.0002599 *** #> lnVARv0i_log(TA)     -0.00036448  0.08630781 -0.0042 0.9966305     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> _____________________________________________________________  coef(m2) #>          (Intercept)              log(Y1)              log(Y2)  #>        -4.3869917305         0.4158744170         0.3700508703  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>         0.5241523719         1.3420979943         0.0474548059  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>         0.0774843635         0.0349966695        -0.2262810941  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>        -0.0576095323        -0.0204629424        -0.0056764377  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>         0.0136391061         0.0188407818        -0.1549250651  #> lnVARv0i_(Intercept)     lnVARv0i_log(TA)  #>        -3.6875872440        -0.0003644791"},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"linear-regression-with-skew-normal-errors","dir":"Articles","previous_headings":"","what":"Linear Regression with Skew-Normal Errors","title":"Introduction to snreg","text":"snreg() function fits linear regression model disturbance term follows skew-normal distribution.","code":""},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"homoskedastic-and-symmetric-model","dir":"Articles","previous_headings":"Linear Regression with Skew-Normal Errors","what":"Homoskedastic and Symmetric Model","title":"Introduction to snreg","text":"","code":"formSV <- NULL     # variance equation formSK <- NULL     # skewness equation  m1 <- snreg(   formula  = spe.tl,   data     = banks07,   ln.var.v = formSV,   skew.v   = formSK ) #>  theta0: #>          (Intercept)              log(Y1)              log(Y2)  #>         -4.386991731          0.415874408          0.370050861  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>          0.524152369          1.342097991          0.047454756  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>          0.077484315          0.034996665         -0.226281101  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>         -0.057609631         -0.020462972         -0.005676474  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>          0.013639077          0.018840745         -0.154925076  #> lnVARv0i_(Intercept) Skew_v0i_(Intercept)  #>         -3.687587268          3.000000000  #>  #> -------------- Regression with skewed errors: --------------- #>  #> Iteration   0 (at starting values):       log likelihood = 5.146960520337 #>  #> Iteration   1 (hessian is provided,   1 in total):   log likelihood = 201.5619797261 #> Iteration   2 (hessian is provided,   2 in total):   log likelihood = 218.5157385369 #> Iteration   3 (hessian is provided,   3 in total):   log likelihood = 219.8304053615 #> Iteration   4 (hessian is provided,   4 in total):   log likelihood = 221.1570395072 #> Iteration   5 (hessian is provided,   5 in total):   log likelihood = 221.4173977326 #> Iteration   6 (hessian is provided,   6 in total):   log likelihood = 221.45910305 #> Iteration   7 (hessian is provided,   7 in total):   log likelihood = 221.4742381631 #> Iteration   8 (hessian is provided,   8 in total):   log likelihood = 221.4742892007 #> Iteration   9 (hessian is provided,   9 in total):   log likelihood = 221.4772909678 #>  #> Convergence given g inv(H) g' = 1.147956e-05 < lmtol #>  #> Final log likelihood = 221.4772909678 #>  #>                         Estimate     Std.Err  Z value    Pr(>z)     #> (Intercept)          -5.88439482  3.00884171  -1.9557  0.050500 .   #> log(Y1)               0.43986913  0.15724371   2.7974  0.005152 **  #> log(Y2)               0.50497847  0.27574767   1.8313  0.067055 .   #> log(W1)               0.54680112  0.27757332   1.9699  0.048846 *   #> log(W2)               1.62221319  1.19336826   1.3594  0.174034     #> I(0.5 * log(Y1)^2)    0.04152960  0.00579831   7.1624 7.929e-13 *** #> I(0.5 * log(Y2)^2)    0.06775246  0.02251267   3.0095  0.002617 **  #> I(0.5 * log(W1)^2)    0.03985513  0.02624261   1.5187  0.128833     #> I(0.5 * log(W2)^2)   -0.28421570  0.32037935  -0.8871  0.375013     #> log(Y1):log(Y2)      -0.05595449  0.01162258  -4.8143 1.477e-06 *** #> log(Y1):log(W1)      -0.02195339  0.01251279  -1.7545  0.079349 .   #> log(Y1):log(W2)       0.00032291  0.04106930   0.0079  0.993727     #> log(Y2):log(W1)       0.01294569  0.01577160   0.8208  0.411747     #> log(Y2):log(W2)       0.00975499  0.05798118   0.1682  0.866391     #> log(W1):log(W2)      -0.15803381  0.06620501  -2.3870  0.016985 *   #> lnVARv0i_(Intercept) -3.01076847  0.11366937 -26.4871 < 2.2e-16 *** #> Skew_v0i_(Intercept)  1.86603587  0.32264117   5.7836 7.311e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> _____________________________________________________________  coef(m1) #>          (Intercept)              log(Y1)              log(Y2)  #>         -5.884394817          0.439869125          0.504978469  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>          0.546801118          1.622213193          0.041529597  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>          0.067752458          0.039855132         -0.284215702  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>         -0.055954492         -0.021953387          0.000322907  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>          0.012945689          0.009754988         -0.158033814  #> lnVARv0i_(Intercept) Skew_v0i_(Intercept)  #>         -3.010768472          1.866035868"},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"heteroskedastic-with-skewed-noise","dir":"Articles","previous_headings":"Linear Regression with Skew-Normal Errors","what":"Heteroskedastic with Skewed Noise","title":"Introduction to snreg","text":"","code":"formSV <- ~ log(TA)   # heteroskedasticity in v formSK <- ~ ER        # skewness driven by equity ratio  m2 <- snreg(   formula  = spe.tl,   data     = banks07,   ln.var.v = formSV,   skew.v   = formSK ) #>  theta0: #>               (Intercept)                   log(Y1)                   log(Y2)  #>              -4.386991731               0.415874408               0.370050861  #>                   log(W1)                   log(W2)        I(0.5 * log(Y1)^2)  #>               0.524152369               1.342097991               0.047454756  #>        I(0.5 * log(Y2)^2)        I(0.5 * log(W1)^2)        I(0.5 * log(W2)^2)  #>               0.077484315               0.034996665              -0.226281101  #>           log(Y1):log(Y2)           log(Y1):log(W1)           log(Y1):log(W2)  #>              -0.057609631              -0.020462972              -0.005676474  #>           log(Y2):log(W1)           log(Y2):log(W2)           log(W1):log(W2)  #>               0.013639077               0.018840745              -0.154925076  #>      lnVARv0i_(Intercept) lnVARv0i_lnVARv0i_log(TA)      Skew_v0i_(Intercept)  #>              -3.687587268               0.000000000               3.000000000  #>      Skew_v0i_Skew_v0i_ER  #>               0.000000000  #>  #> ----------------- Regression with skewed errors: ----------------- #>  #> Iteration   0 (at starting values):       log likelihood = 5.146960520337 #>  #> Iteration   1 (hessian is provided,   1 in total):   log likelihood = 204.6988401214 #> Iteration   2 (hessian is provided,   2 in total):   log likelihood = 221.6390613234 #> Iteration   3 (hessian is provided,   3 in total):   log likelihood = 224.8771023643 #> Iteration   4 (hessian is provided,   4 in total):   log likelihood = 225.6867346145 #> Iteration   5 (hessian is provided,   5 in total):   log likelihood = 225.9380532273 #> Iteration   6 (hessian is provided,   6 in total):   log likelihood = 226.0484166119 #> Iteration   7 (hessian is provided,   7 in total):   log likelihood = 226.0721225638 #> Iteration   8 (hessian is provided,   8 in total):   log likelihood = 226.0820635056 #> Iteration   9 (hessian is provided,   9 in total):   log likelihood = 226.0835072457 #> Iteration  10 (hessian is provided,  10 in total):   log likelihood = 226.0909506421 #>  #> Convergence given g inv(H) g' = 9.357213e-05 < lmtol #>  #> Final log likelihood = 226.0909506421 #>  #>                              Estimate     Std.Err Z value    Pr(>z)     #> (Intercept)               -5.71501334  2.98991742 -1.9114  0.055950 .   #> log(Y1)                    0.45216186  0.15708195  2.8785  0.003996 **  #> log(Y2)                    0.64671047  0.28153250  2.2971  0.021613 *   #> log(W1)                    0.48917765  0.27664356  1.7683  0.077018 .   #> log(W2)                    1.15530138  1.17400483  0.9841  0.325082     #> I(0.5 * log(Y1)^2)         0.04070906  0.00590546  6.8935 5.445e-12 *** #> I(0.5 * log(Y2)^2)         0.06170967  0.02265802  2.7235  0.006459 **  #> I(0.5 * log(W1)^2)         0.04271441  0.02667730  1.6012  0.109343     #> I(0.5 * log(W2)^2)        -0.15999322  0.31994376 -0.5001  0.617028     #> log(Y1):log(Y2)           -0.05757860  0.01197968 -4.8064 1.537e-06 *** #> log(Y1):log(W1)           -0.01887894  0.01276125 -1.4794  0.139035     #> log(Y1):log(W2)            0.00165155  0.04117676  0.0401  0.968006     #> log(Y2):log(W1)            0.00516054  0.01583258  0.3259  0.744467     #> log(Y2):log(W2)           -0.00022261  0.05922730 -0.0038  0.997001     #> log(W1):log(W2)           -0.13107647  0.06626509 -1.9781  0.047922 *   #> lnVARv0i_(Intercept)      -0.89452888  1.03829604 -0.8615  0.388943     #> lnVARv0i_lnVARv0i_log(TA) -0.17730037  0.08736480 -2.0294  0.042415 *   #> Skew_v0i_(Intercept)       3.10567750  0.76059557  4.0832 4.442e-05 *** #> Skew_v0i_Skew_v0i_ER      -9.55208958  4.87607389 -1.9590  0.050116 .   #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> __________________________________________________________________  coef(m2) #>               (Intercept)                   log(Y1)                   log(Y2)  #>             -5.7150133374              0.4521618623              0.6467104718  #>                   log(W1)                   log(W2)        I(0.5 * log(Y1)^2)  #>              0.4891776489              1.1553013814              0.0407090640  #>        I(0.5 * log(Y2)^2)        I(0.5 * log(W1)^2)        I(0.5 * log(W2)^2)  #>              0.0617096653              0.0427144069             -0.1599932243  #>           log(Y1):log(Y2)           log(Y1):log(W1)           log(Y1):log(W2)  #>             -0.0575785975             -0.0188789363              0.0016515541  #>           log(Y2):log(W1)           log(Y2):log(W2)           log(W1):log(W2)  #>              0.0051605363             -0.0002226092             -0.1310764688  #>      lnVARv0i_(Intercept) lnVARv0i_lnVARv0i_log(TA)      Skew_v0i_(Intercept)  #>             -0.8945288842             -0.1773003673              3.1056774984  #>      Skew_v0i_Skew_v0i_ER  #>             -9.5520895773"},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"stochastic-frontier-model-with-skew-normal-errors","dir":"Articles","previous_headings":"","what":"Stochastic Frontier Model with Skew-Normal Errors","title":"Introduction to snreg","text":"snsf() function performs maximum likelihood estimation parameters technical cost efficiencies Stochastic Frontier Model skew-normally distributed error term.","code":""},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"homoskedastic-and-symmetric-model-1","dir":"Articles","previous_headings":"Stochastic Frontier Model with Skew-Normal Errors","what":"Homoskedastic and Symmetric Model","title":"Introduction to snreg","text":"","code":"myprod <- FALSE  formSV <- NULL   # variance equation formSK <- NULL   # skewness equation  m1 <- snsf(   formula  = spe.tl,   data     = banks07,   prod     = myprod,   ln.var.v = formSV,   skew.v   = formSK ) #>  #> -------------- Regression with skewed errors: --------------- #>  #> initial  value -105.392823  #> iter   2 value -105.561746 #> iter   3 value -105.568000 #> iter   4 value -105.836407 #> iter   5 value -106.255928 #> iter   6 value -107.989401 #> iter   7 value -129.390401 #> iter   8 value -148.614164 #> iter   8 value -148.614164 #> iter   9 value -148.627674 #> iter  10 value -148.628304 #> iter  10 value -148.628304 #> iter  10 value -148.628304 #> final  value -148.628304  #> converged #>                         Estimate     Std.Err  Z value    Pr(>z)     #> X(Intercept)         -4.40500089  3.80254827  -1.1584  0.246687     #> Xlog(Y1)              0.45706967  0.18307828   2.4966  0.012540 *   #> Xlog(Y2)              0.31560584  0.33532057   0.9412  0.346599     #> Xlog(W1)              0.48827077  0.38637994   1.2637  0.206335     #> Xlog(W2)              1.29215252  1.70829901   0.7564  0.449411     #> XI(0.5 * log(Y1)^2)   0.06252731  0.00718640   8.7008 < 2.2e-16 *** #> XI(0.5 * log(Y2)^2)   0.19680294  0.03130033   6.2876 3.225e-10 *** #> XI(0.5 * log(W1)^2)   0.05041646  0.03723206   1.3541  0.175700     #> XI(0.5 * log(W2)^2)  -0.28522159  0.46697561  -0.6108  0.541342     #> Xlog(Y1):log(Y2)     -0.14258698  0.00610987 -23.3372 < 2.2e-16 *** #> Xlog(Y1):log(W1)      0.00029592  0.01705705   0.0173  0.986158     #> Xlog(Y1):log(W2)      0.17610934  0.05558196   3.1685  0.001532 **  #> Xlog(Y2):log(W1)      0.01454480  0.02162340   0.6726  0.501175     #> Xlog(Y2):log(W2)     -0.09354141  0.07710129  -1.2132  0.225043     #> Xlog(W1):log(W2)     -0.21197450  0.09475124  -2.2372  0.025275 *   #> lnVARv0i_(Intercept) -2.66540968  0.11013951 -24.2003 < 2.2e-16 *** #> Skew_v0i_(Intercept)  0.98854923  0.03434255  28.7850 < 2.2e-16 *** #> sv                    0.26376286  0.00766250  34.4226 < 2.2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> _____________________________________________________________ #>  theta0: #>          (Intercept)              log(Y1)              log(Y2)  #>        -4.4050008900         0.4570696682         0.3156058426  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>         0.4882707672         1.2921525200         0.0625273146  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>         0.1968029394         0.0504164557        -0.2852215911  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>        -0.1425869800         0.0002959179         0.1761093362  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>         0.0145448021        -0.0935414140        -0.2119744969  #> lnVARv0i_(Intercept) Skew_v0i_(Intercept) lnVARu0i_(Intercept)  #>        -4.2020745955         0.3982617494        -4.5984104618  #>  #> ---------------------- The main model: ---------------------- #>  #> Iteration   0 (at starting values):       log likelihood = 21.64346032248 #>  #> Iteration   1 (hessian is provided,   1 in total):   log likelihood = 186.4880063145 #> Iteration   2 (hessian is provided,   2 in total):   log likelihood = 214.3430643968 #> Iteration   3 (hessian is provided,   3 in total):   log likelihood = 220.957921695 #> Iteration   4 (hessian is provided,   4 in total):   log likelihood = 223.1040419712 #> Iteration   5 (hessian is provided,   5 in total):   log likelihood = 224.3725358921 #> Iteration   6 (hessian is provided,   6 in total):   log likelihood = 224.6133195507 #> Iteration   7 (hessian is provided,   7 in total):   log likelihood = 224.7096271178 #> Iteration   8 (hessian is provided,   8 in total):   log likelihood = 224.7298349674 #> Iteration   9 (hessian is provided,   9 in total):   log likelihood = 224.8005650898 #> Iteration  10 (hessian is provided,  10 in total):   log likelihood = 224.8011109934 #> Iteration  11 (hessian is provided,  11 in total):   log likelihood = 224.8019248405 #> Iteration  12 (hessian is provided,  12 in total):   log likelihood = 224.8021079368 #> Iteration  13 (hessian is provided,  13 in total):   log likelihood = 224.8054321542 #> Iteration  14 (hessian is provided,  14 in total):   log likelihood = 224.8420044777 #> Iteration  15 (hessian is provided,  15 in total):   log likelihood = 225.4135588864 #> Iteration  16 (hessian is provided,  16 in total):   log likelihood = 225.5282232035 #> Iteration  17 (hessian is provided,  17 in total):   log likelihood = 225.533351752 #> Iteration  18 (hessian is provided,  18 in total):   log likelihood = 225.5368333384 #> Iteration  19 (hessian is provided,  19 in total):   log likelihood = 225.5371105355 #> Iteration  20 (hessian is provided,  20 in total):   log likelihood = 225.539300346 #> Iteration  21 (hessian is provided,  21 in total):   log likelihood = 225.539317247 #> Iteration  22 (hessian is provided,  22 in total):   log likelihood = 225.539324279 #>  #> Convergence given g inv(H) g' = 1.027857e-06 < lmtol #>  #> Final log likelihood = 225.539324279 #>  #>  #> Log likelihood maximization completed in #> 0.183 seconds #> _____________________________________________________________ #>  #> Cross-sectional stochastic (cost) frontier model #>  #> Distributional assumptions #>  #>   Component      Distribution Assumption    #> 1 Random noise:  skew normal  homoskedastic #> 2 Inefficiency:  exponential  homoskedastic #>  #> Number of observations = 500 #>  #> -------------------- Estimation results: -------------------- #>  #>                           Coef.        SE       z       P>|z| #> _____________________________________________________________ #> Frontier #>                                                                   #> (Intercept)             -6.3606     3.0602   -2.08     0.0377 *   #> log(Y1)                  0.4425     0.1767    2.50     0.0123 *   #> log(Y2)                  0.5660     0.2753    2.06     0.0398 *   #> log(W1)                  0.4983     0.2835    1.76     0.0788 .   #> log(W2)                  1.6557     1.1889    1.39     0.1637     #> I(0.5 * log(Y1)^2)       0.0449     0.0066    6.76     0.0000 *** #> I(0.5 * log(Y2)^2)       0.0650     0.0222    2.93     0.0034 **  #> I(0.5 * log(W1)^2)       0.0363     0.0258    1.41     0.1597     #> I(0.5 * log(W2)^2)      -0.3099     0.3170   -0.98     0.3283     #> log(Y1):log(Y2)         -0.0586     0.0117   -4.99     0.0000 *** #> log(Y1):log(W1)         -0.0227     0.0127   -1.78     0.0750 .   #> log(Y1):log(W2)         -0.0006     0.0420   -0.01     0.9895     #> log(Y2):log(W1)          0.0117     0.0152    0.77     0.4393     #> log(Y2):log(W2)          0.0106     0.0563    0.19     0.8505     #> log(W1):log(W2)         -0.1375     0.0682   -2.02     0.0438 *   #> ------------------------------------------------------------- #> Variance of the random noise component: log(sigma_v^2) #>                                                                   #> lnVARv0i_(Intercept)    -3.8207     0.2255  -16.94     0.0000 *** #> ------------------------------------------------------------- #> Skewness of the random noise component: `alpha` #>                                                                   #> Skew_v0i_(Intercept)    -1.5007     0.8755   -1.71     0.0865 .   #> ------------------------------------------------------------- #> Inefficiency component: log(sigma_u^2) #>                                                                   #> lnVARu0i_(Intercept)    -4.3422     0.2398  -18.11     0.0000 *** #> _____________________________________________________________ #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> --------------- Summary of cost efficiencies: --------------- #>  #>                 JLMS:= exp(-E[ui|ei]) #>  #>       TE_JLMS #> Obs       500 #> NAs         0 #> Mean   0.8955 #> StDev  0.0715 #> IQR    0.0645 #> Min    0.4559 #> 5%     0.7420 #> 10%    0.7959 #> 25%    0.8780 #> 50%    0.9208 #> 75%    0.9425 #> 90%    0.9520 #> Max    0.9691  coef(m1) #>          (Intercept)              log(Y1)              log(Y2)  #>        -6.3606134654         0.4425312174         0.5660453675  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>         0.4983319531         1.6557355502         0.0448519992  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>         0.0649995029         0.0362747554        -0.3099280819  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>        -0.0586056701        -0.0226917826        -0.0005509121  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>         0.0117430476         0.0106095399        -0.1375404433  #> lnVARv0i_(Intercept) Skew_v0i_(Intercept) lnVARu0i_(Intercept)  #>        -3.8206601915        -1.5006628040        -4.3422317628"},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"heteroskedastic-with-skewed-noise-1","dir":"Articles","previous_headings":"Stochastic Frontier Model with Skew-Normal Errors","what":"Heteroskedastic with Skewed Noise","title":"Introduction to snreg","text":"","code":"formSV <- ~ log(TA)      # heteroskedastic variance formSK <- ~ ER           # skewness driver  m2 <- snsf(   formula  = spe.tl,   data     = banks07,   prod     = myprod,   ln.var.v = formSV,   skew.v   = formSK ) #>  #> -------------- Regression with skewed errors: --------------- #>  #> initial  value -105.392823  #> iter   2 value -105.561746 #> iter   3 value -105.568000 #> iter   4 value -105.836407 #> iter   5 value -106.255928 #> iter   6 value -107.989401 #> iter   7 value -129.390401 #> iter   8 value -148.614164 #> iter   8 value -148.614164 #> iter   9 value -148.627674 #> iter  10 value -148.628304 #> iter  10 value -148.628304 #> iter  10 value -148.628304 #> final  value -148.628304  #> converged #>                         Estimate     Std.Err  Z value    Pr(>z)     #> X(Intercept)         -4.40500089  3.80254827  -1.1584  0.246687     #> Xlog(Y1)              0.45706967  0.18307828   2.4966  0.012540 *   #> Xlog(Y2)              0.31560584  0.33532057   0.9412  0.346599     #> Xlog(W1)              0.48827077  0.38637994   1.2637  0.206335     #> Xlog(W2)              1.29215252  1.70829901   0.7564  0.449411     #> XI(0.5 * log(Y1)^2)   0.06252731  0.00718640   8.7008 < 2.2e-16 *** #> XI(0.5 * log(Y2)^2)   0.19680294  0.03130033   6.2876 3.225e-10 *** #> XI(0.5 * log(W1)^2)   0.05041646  0.03723206   1.3541  0.175700     #> XI(0.5 * log(W2)^2)  -0.28522159  0.46697561  -0.6108  0.541342     #> Xlog(Y1):log(Y2)     -0.14258698  0.00610987 -23.3372 < 2.2e-16 *** #> Xlog(Y1):log(W1)      0.00029592  0.01705705   0.0173  0.986158     #> Xlog(Y1):log(W2)      0.17610934  0.05558196   3.1685  0.001532 **  #> Xlog(Y2):log(W1)      0.01454480  0.02162340   0.6726  0.501175     #> Xlog(Y2):log(W2)     -0.09354141  0.07710129  -1.2132  0.225043     #> Xlog(W1):log(W2)     -0.21197450  0.09475124  -2.2372  0.025275 *   #> lnVARv0i_(Intercept) -2.66540968  0.11013951 -24.2003 < 2.2e-16 *** #> Skew_v0i_(Intercept)  0.98854923  0.03434255  28.7850 < 2.2e-16 *** #> sv                    0.26376286  0.00766250  34.4226 < 2.2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #> _____________________________________________________________ #>  theta0: #>          (Intercept)              log(Y1)              log(Y2)  #>        -4.405001e+00         4.570697e-01         3.156058e-01  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>         4.882708e-01         1.292153e+00         6.252731e-02  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>         1.968029e-01         5.041646e-02        -2.852216e-01  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>        -1.425870e-01         2.959179e-04         1.761093e-01  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>         1.454480e-02        -9.354141e-02        -2.119745e-01  #> lnVARv0i_(Intercept)     lnVARv0i_log(TA) Skew_v0i_(Intercept)  #>        -4.202075e+00         2.212626e-16         3.982617e-01  #>          Skew_v0i_ER lnVARu0i_(Intercept)  #>         0.000000e+00        -4.598410e+00  #>  #> ---------------------- The main model: ---------------------- #>  #> Iteration   0 (at starting values):       log likelihood = 21.64346032248 #>  #> Iteration   1 (hessian is provided,   1 in total):   log likelihood = 133.2018982456 #> Iteration   2 (hessian is provided,   2 in total):   log likelihood = 183.2824024606 #> Iteration   3 (hessian is provided,   3 in total):   log likelihood = 214.7412845581 #> Iteration   4 (hessian is provided,   4 in total):   log likelihood = 223.1763227676 #> Iteration   5 (hessian is provided,   5 in total):   log likelihood = 226.655477596 #> Iteration   6 (hessian is provided,   6 in total):   log likelihood = 226.7105002202 #> Iteration   7 (hessian is provided,   7 in total):   log likelihood = 226.8074129256 #> Iteration   8 (hessian is provided,   8 in total):   log likelihood = 226.8082101988 #> Iteration   9 (hessian is provided,   9 in total):   log likelihood = 226.8082151929 #> Iteration  10 (hessian is provided,  10 in total):   log likelihood = 226.808224564 #>  #> Convergence given g inv(H) g' = 2.529443e-06 < lmtol #>  #> Final log likelihood = 226.808224564 #>  #>  #> Log likelihood maximization completed in #> 0.103 seconds #> _____________________________________________________________ #>  #> Cross-sectional stochastic (cost) frontier model #>  #> Distributional assumptions #>  #>   Component      Distribution Assumption      #> 1 Random noise:  skew normal  heteroskedastic #> 2 Inefficiency:  exponential  homoskedastic   #>  #> Number of observations = 500 #>  #> -------------------- Estimation results: -------------------- #>  #>                           Coef.        SE       z       P>|z| #> _____________________________________________________________ #> Frontier #>                                                                   #> (Intercept)             -5.9441     3.0205   -1.97     0.0491 *   #> log(Y1)                  0.4589     0.1647    2.79     0.0053 **  #> log(Y2)                  0.6135     0.2820    2.18     0.0296 *   #> log(W1)                  0.5168     0.2747    1.88     0.0599 .   #> log(W2)                  1.2707     1.1934    1.06     0.2870     #> I(0.5 * log(Y1)^2)       0.0414     0.0061    6.81     0.0000 *** #> I(0.5 * log(Y2)^2)       0.0614     0.0226    2.72     0.0065 **  #> I(0.5 * log(W1)^2)       0.0439     0.0262    1.68     0.0938 .   #> I(0.5 * log(W2)^2)      -0.2078     0.3247   -0.64     0.5223     #> log(Y1):log(Y2)         -0.0575     0.0120   -4.79     0.0000 *** #> log(Y1):log(W1)         -0.0215     0.0128   -1.68     0.0927 .   #> log(Y1):log(W2)          0.0000     0.0417    0.00     0.9997     #> log(Y2):log(W1)          0.0068     0.0158    0.43     0.6682     #> log(Y2):log(W2)          0.0086     0.0589    0.15     0.8836     #> log(W1):log(W2)         -0.1368     0.0661   -2.07     0.0384 *   #> ------------------------------------------------------------- #> Variance of the random noise component: log(sigma_v^2) #>                                                                   #> lnVARv0i_(Intercept)    -1.8839     1.6595   -1.14     0.2563     #> lnVARv0i_log(TA)        -0.1558     0.1328   -1.17     0.2407     #> ------------------------------------------------------------- #> Skewness of the random noise component: `alpha` #>                                                                   #> Skew_v0i_(Intercept)     2.0043     1.0468    1.91     0.0555 .   #> Skew_v0i_ER             -7.2632     5.0581   -1.44     0.1510     #> ------------------------------------------------------------- #> Inefficiency component: log(sigma_u^2) #>                                                                   #> lnVARu0i_(Intercept)    -4.6407     0.3416  -13.58     0.0000 *** #> _____________________________________________________________ #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> --------------- Summary of cost efficiencies: --------------- #>  #>                 JLMS:= exp(-E[ui|ei]) #>  #>       TE_JLMS #> Obs       500 #> NAs         0 #> Mean   0.9084 #> StDev  0.0564 #> IQR    0.0547 #> Min    0.5206 #> 5%     0.8096 #> 10%    0.8379 #> 25%    0.8903 #> 50%    0.9241 #> 75%    0.9450 #> 90%    0.9568 #> Max    0.9758  coef(m2) #>          (Intercept)              log(Y1)              log(Y2)  #>        -5.944090e+00         4.589482e-01         6.134700e-01  #>              log(W1)              log(W2)   I(0.5 * log(Y1)^2)  #>         5.167646e-01         1.270694e+00         4.138294e-02  #>   I(0.5 * log(Y2)^2)   I(0.5 * log(W1)^2)   I(0.5 * log(W2)^2)  #>         6.141001e-02         4.385504e-02        -2.077538e-01  #>      log(Y1):log(Y2)      log(Y1):log(W1)      log(Y1):log(W2)  #>        -5.745504e-02        -2.151307e-02         1.351571e-05  #>      log(Y2):log(W1)      log(Y2):log(W2)      log(W1):log(W2)  #>         6.752251e-03         8.627646e-03        -1.368348e-01  #> lnVARv0i_(Intercept)     lnVARv0i_log(TA) Skew_v0i_(Intercept)  #>        -1.883867e+00        -1.558322e-01         2.004266e+00  #>          Skew_v0i_ER lnVARu0i_(Intercept)  #>        -7.263169e+00        -4.640750e+00"},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"acknowledgments","dir":"Articles","previous_headings":"","what":"Acknowledgments","title":"Introduction to snreg","text":"R package snreg computes Owenâ€™s T function using C code written John Burkardt. implementation, distributed MIT license, publicly accessible https://people.sc.fsu.edu/~jburkardt/c_src/owen/owen.html.","code":""},{"path":"https://olegbadunenko.github.io/snreg/articles/snreg-manual.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Introduction to snreg","text":"Badunenko, O. Henderson, D.J. (2023). Production analysis asymmetric noise. Journal Productivity Analysis, 61(1), 1â€“18. https://doi.org/10.1007/s11123-023-00680-5","code":""},{"path":"https://olegbadunenko.github.io/snreg/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Oleg Badunenko. Author, maintainer. John Burkardt. Contributor, copyright holder.           Author C code Owen T function","code":""},{"path":"https://olegbadunenko.github.io/snreg/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Badunenko O (2026). snreg: Regression Skew-Normally Distributed Error Term. R package version 1.1.0, https://olegbadunenko.github.io/snreg/.","code":"@Manual{,   title = {snreg: Regression with Skew-Normally Distributed Error Term},   author = {Oleg Badunenko},   year = {2026},   note = {R package version 1.1.0},   url = {https://olegbadunenko.github.io/snreg/}, }"},{"path":"https://olegbadunenko.github.io/snreg/index.html","id":"regression-with-skew-normally-distributed-error-term","dir":"","previous_headings":"","what":"Regression with Skew-Normally Distributed Error Term","title":"Regression with Skew-Normally Distributed Error Term","text":"snreg package offers set methods conducting regression analysis model errors follow skewâ€‘normal distribution.","code":""},{"path":"https://olegbadunenko.github.io/snreg/index.html","id":"the-framework","dir":"","previous_headings":"","what":"The framework","title":"Regression with Skew-Normally Distributed Error Term","text":"snreg package implements framework developed Oleg Badunenko Daniel J. Henderson (2023). â€œProduction analysis asymmetric noiseâ€. Journal Productivity Analysis, 61(1), 1â€“18. DOI R commands snreg snsf estimate models skew-normal errors written maintained Oleg Badunenko (oleg.badunenko@brunel.ac.uk).","code":""},{"path":"https://olegbadunenko.github.io/snreg/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Regression with Skew-Normally Distributed Error Term","text":"R package snreg computes Owenâ€™s T function using C code written John Burkardt. implementation, distributed MIT license, publicly accessible https://people.sc.fsu.edu/~jburkardt/c_src/owen/owen.html.","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/index.html","id":"id_1-install-the-devtools-package","dir":"","previous_headings":"","what":"1. Install the devtools package","title":"Regression with Skew-Normally Distributed Error Term","text":"Install devtools CRAN (havenâ€™t already):","code":"# Install only if not already installed if (!requireNamespace(\"remotes\", quietly = TRUE)) {   install.packages(\"remotes\") }"},{"path":"https://olegbadunenko.github.io/snreg/index.html","id":"id_2-install-the-package-from-github","dir":"","previous_headings":"","what":"2. Install the package from GitHub","title":"Regression with Skew-Normally Distributed Error Term","text":"Install snreg package GitHub. code, installing snreg package created OlegBadunenko.","code":"# Install only if not already installed if (!requireNamespace(\"snreg\", quietly = TRUE)) {   remotes::install_github(\"OlegBadunenko/snreg\", dependencies = TRUE, build_vignettes = FALSE) } else {   message(\"Package 'snreg' is already installed; skipping.\") }"},{"path":"https://olegbadunenko.github.io/snreg/index.html","id":"id_3-load-the-installed-package","dir":"","previous_headings":"","what":"3. Load the installed package","title":"Regression with Skew-Normally Distributed Error Term","text":"","code":"library(snreg)"},{"path":"https://olegbadunenko.github.io/snreg/index.html","id":"bulb-notes--tips","dir":"","previous_headings":"","what":"ðŸ’¡ Notes & Tips","title":"Regression with Skew-Normally Distributed Error Term","text":"Works identically across R, RStudio, Windows, Mac, Linux. GitHub packages may already available environments like npsf. installation fails, common causes include missing build tools, incorrect repo names, network restrictions.","code":""},{"path":"https://olegbadunenko.github.io/snreg/index.html","id":"illustration-and-uses","dir":"","previous_headings":"","what":"Illustration and Uses","title":"Regression with Skew-Normally Distributed Error Term","text":"article guides code illustrates functionality package using subset banking data (banks07) available package.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Owen's T Function T(h, a) â€” TOwen","title":"Compute Owen's T Function T(h, a) â€” TOwen","text":"TOwen1 computes Owen's \\(T\\)-function variant (related special function) vectors h based t function https://people.sc.fsu.edu/~jburkardt/c_src/owen/owen.html. Non-finite inputs (h ) produce NA corresponding positions, finite pairs computed C vectorized fashion.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Owen's T Function T(h, a) â€” TOwen","text":"","code":"TOwen(h, a, threads = 1)"},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Owen's T Function T(h, a) â€” TOwen","text":"h numeric vector \\(h\\) arguments. numeric vector \\(\\) arguments. Must either length h length 1 (recycled standard R rules). threads integer. Number threads request C implementation (supported). Default 1.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Owen's T Function T(h, a) â€” TOwen","text":"numeric vector length length(h) containing \\(T(h_i, a_i)\\). Elements either h_i a_i finite NA. returned object given class \"snreg\" downstream compatibility packageâ€™s print/summary helpers.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Owen's T Function T(h, a) â€” TOwen","text":"Owen's T Function via C Backend Owen's \\(T\\) function commonly defined $$T(h, ) \\;=\\; \\frac{1}{2\\pi} \\int_{0}^{} \\frac{\\exp\\!\\left(-\\tfrac{1}{2}h^2 (1+t^2)\\right)}{1+t^2} \\, dt,$$ real \\(h\\) \\(\\). function accepts vector inputs : Computes results entries h finite. Returns NA either h non-finite. Optionally passes threads hint C backend (ignored supported).","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Owen's T Function T(h, a) â€” TOwen","text":"","code":"if (FALSE) { # \\dontrun{   # Basic usage. Vectorized 'a'   h <- c(-1, 0, 1, 2)   a <- 0.5   TOwen(h, a)    # Vectorized 'a' with non-finite entries; non-finite entries yield NA   a2 <- c(0.2, NA, 1, Inf)   TOwen(h, a2) } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen1.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Owen-like Function TOwen1(h, a) â€” TOwen1","title":"Compute Owen-like Function TOwen1(h, a) â€” TOwen1","text":"TOwen1 computes Owen's \\(T\\)-function variant (related special function) vectors h based tha function https://people.sc.fsu.edu/~jburkardt/c_src/owen/owen.html. Non-finite inputs h yield NA corresponding positions.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Owen-like Function TOwen1(h, a) â€” TOwen1","text":"","code":"TOwen1(h, a, threads = 1)"},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Owen-like Function TOwen1(h, a) â€” TOwen1","text":"threads integer. Number threads request C implementation (supported). Default 1.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Owen-like Function TOwen1(h, a) â€” TOwen1","text":"numeric vector length length(h) computed values. Elements either h non-finite NA. returned vector given class \"snreg\" downstream compatibility.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Owen-like Function TOwen1(h, a) â€” TOwen1","text":"Owen's T Function Variant via C Backend thin R wrapper around native routine signature:","code":"void TOwen1(int *n, double *h, double *a, double *out, int *threads)"},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/reference/TOwen1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Owen-like Function TOwen1(h, a) â€” TOwen1","text":"","code":"if (FALSE) { # \\dontrun{   library(snreg)    # Basic usage. Vectorized 'a':   h <- c(-1, 0, 1, 2)   a <- 0.3   TOwen1(h, a)    # Vectorized 'a' with non-finite entries:   a2 <- c(0.2, NA, 1, Inf)   TOwen1(h, a2) } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/banks07.html","id":null,"dir":"Reference","previous_headings":"","what":"U.S. Commercial Banks Data â€” banks07","title":"U.S. Commercial Banks Data â€” banks07","text":"banks07 data frame containing selected variables 500 U.S. commercial banks, randomly sampled approximately 5000 banks, based dataset Koetter et al. (2012) year 2007. dataset provided solely illustration pedagogical purposes suitable empirical research.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/banks07.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"U.S. Commercial Banks Data â€” banks07","text":"","code":"data(banks07)"},{"path":"https://olegbadunenko.github.io/snreg/reference/banks07.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"U.S. Commercial Banks Data â€” banks07","text":"data frame following variables: year Year (2007). id Entity (bank) identifier. TA Gross total assets. LLP Loan loss provisions. Y1 Total securities (thousands USD). Y2 Total loans leases (thousands USD). W1 Cost fixed assets divided cost borrowed funds. W2 Cost labor (thousands USD) divided cost borrowed funds. ER Equity--assets ratio (gross). TC Total operating cost. LA Ratio total loans leases gross total assets.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/banks07.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"U.S. Commercial Banks Data â€” banks07","text":"http://qed.econ.queensu.ca/jae/2014-v29.2/restrepo-tobon-kumbhakar/","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/banks07.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"U.S. Commercial Banks Data â€” banks07","text":"U.S. Commercial Banks Data (2007) dataset created sampling transforming variables shown section Examples. intended illustrate usage functions package (e.g. stochastic frontier models skew-normal noise).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/banks07.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"U.S. Commercial Banks Data â€” banks07","text":"Koetter, M., Kolari, J., & Spierdijk, L. (2012). Enjoying quiet life deregulation? Evidence adjusted Lerner indices U.S. banks. Review Economics Statistics, 94(2), 462â€“480. Restrepo-Tobon, D. & Kumbhakar, S. (2014). Enjoying quiet life deregulation? Quite. Journal Applied Econometrics, 29(2), 333â€“343.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/banks07.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"U.S. Commercial Banks Data â€” banks07","text":"","code":"if (FALSE) { # \\dontrun{  ## ------------------------------------------------------------------ ## Construct sample panel dataset (banks00_07) ## ------------------------------------------------------------------  # Download data from the link in \"Source\" banks00_07 <- read.delim(\"2b_QLH.txt\")  # rename 'entity' to 'id' colnames(banks00_07)[colnames(banks00_07) == \"entity\"] <- \"id\"  # keep only years 2000â€“2007 banks00_07 <- banks00_07[   banks00_07$year >= 2000 & banks00_07$year <= 2007, ]  # restrict sample to interquartile range of total assets q1q3 <- quantile(banks00_07$TA, probs = c(.25, .75)) banks00_07 <- banks00_07[   banks00_07$TA >= q1q3[1] & banks00_07$TA <= q1q3[2], ]  # generate required variables banks00_07$TC <- banks00_07$TOC banks00_07$ER <- banks00_07$Z  / banks00_07$TA   # Equity ratio banks00_07$LA <- banks00_07$Y2 / banks00_07$TA   # Loans-to-assets ratio  # keep only needed variables keep.vars <- c(\"id\", \"year\", \"Ti\", \"TC\", \"Y1\", \"Y2\", \"W1\",\"W2\",                \"ER\", \"LA\", \"TA\", \"LLP\") banks00_07 <- banks00_07[, colnames(banks00_07) %in% keep.vars]  # number of periods per id t0 <- as.vector( by(banks00_07$id, banks00_07$id,                     FUN = function(qq) length(qq)) ) banks00_07$Ti <- rep(t0, times = t0)  # keep if Ti > 4 banks00_07 <- banks00_07[banks00_07$Ti > 4, ]  # complete observations only banks00_07 <- banks00_07[complete.cases(banks00_07), ]  # sample 500 banks at random set.seed(816376586) id_names <- unique(banks00_07$id) ids2choose <- sample(id_names, 500) banks00_07 <- banks00_07[banks00_07$id %in% ids2choose, ]  # recompute Ti t0 <- as.vector( by(banks00_07$id, banks00_07$id,                     FUN = function(qq) length(qq)) ) banks00_07$Ti <- rep(t0, times = t0) banks00_07 <- banks00_07[banks00_07$Ti > 4, ]  # sort banks00_07 <- banks00_07[order(banks00_07$id, banks00_07$year), ]   banks07 <- banks00_07[banks00_07$year == 2007, ]  } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/coef.snreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Model Coefficients â€” coef.snreg","title":"Extract Model Coefficients â€” coef.snreg","text":"coef.snreg S3 method extracting estimated regression coefficients object class \"snreg\".","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/coef.snreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Model Coefficients â€” coef.snreg","text":"","code":"# S3 method for class 'snreg' coef(obj, ...)"},{"path":"https://olegbadunenko.github.io/snreg/reference/coef.snreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Model Coefficients â€” coef.snreg","text":"obj object class \"snreg\", typically returned snreg. ... additional arguments (currently unused).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/coef.snreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Model Coefficients â€” coef.snreg","text":"numeric vector containing model coefficients.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/coef.snreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Model Coefficients â€” coef.snreg","text":"Coefficients snreg Model method simply returns coef component stored inside fitted \"snreg\" object. object contain coefficient estimates (e.g., estimation completed scaffold), informative error raised.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/coef.snreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Model Coefficients â€” coef.snreg","text":"","code":"if (FALSE) { # \\dontrun{   m <- snreg(y ~ x1 + x2, data = df)   coef(m) } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/lm.mle.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Regression via MLE â€” lm.mle","title":"Linear Regression via MLE â€” lm.mle","text":"lm.mle fits linear regression model maximum likelihood, allowing optional multiplicative heteroskedasticity disturbance variance via log-linear specification provided ln.var.v.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/lm.mle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Regression via MLE â€” lm.mle","text":"","code":"lm.mle(   formula,   data,   subset,   ln.var.v = NULL,   technique = c(\"bfgs\"),   lmtol = 1e-05,   reltol = 1e-12,   maxit = 199,   optim.report = 1,   optim.trace = 10,   print.level = 3,   digits = 4,   only.data = FALSE,   ... )"},{"path":"https://olegbadunenko.github.io/snreg/reference/lm.mle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Regression via MLE â€” lm.mle","text":"formula object class formula specifying regression: typically y ~ x1 + ..., y dependent variable x's regressors. data optional data.frame containing variables referenced formula. found data, variables taken environment(formula). subset optional logical numeric vector specifying subset observations used estimation. ln.var.v optional one-sided formula; e.g. ln.var.v ~ z1 + z2. provided, error variance modeled \\(\\log(\\sigma_i^2) = w_i^\\top \\gamma_v\\). NULL, variance homoskedastic. technique character vector specifying preferred optimization routine(s) order preference. Recognized keywords (future implementation) include \"bfgs\" \"bhhh\", \"nm\" (Nelderâ€“Mead), \"bfgs\", \"cg\". Default \"bfgs\". scaffold records execute chosen routine. lmtol numeric. Convergence tolerance based scaled gradient (applicable). Default 1e-5. reltol numeric. Relative convergence tolerance likelihood maximization. Default 1e-12. maxit integer. Maximum number iterations optimizer. Default 199. optim.report integer. Verbosity level reporting progress (implemented). Default 1. optim.trace integer. Trace level optimization (implemented). Default 1. print.level integer. Printing level summaries. Default 3. digits integer. Number digits printing. Default 4. .data logical. TRUE, returns constructed data/matrices without estimation. Default FALSE. ... additional arguments reserved future methods (e.g., bounds, penalties).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/lm.mle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Regression via MLE â€” lm.mle","text":"list class \"snreg\" containing (extending) fields returned optim: par â€” numeric vector MLE parameter estimates. value â€” numeric scalar: maximized log-likelihood value. ll â€” numeric scalar: maximized log-likelihood value. counts, convergence, message â€” standard optim outputs. hessian â€” observed Hessian solution (returned optim(hessian=TRUE)). coef â€” named numeric vector equal par (estimates). vcov â€” varianceâ€“covariance matrix, computed solve(-hessian). sds â€” standard errors, sqrt(diag(vcov)). ctab â€” coefficient table columns:     Estimate, Std.Err, Z value, Pr(>z). esample â€” logical vector indicating observations used estimation. n â€” scalar, number observations estimation sample. object inherits default optim components assigned class \"snreg\".","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/lm.mle.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear Regression via MLE â€” lm.mle","text":"Linear Model Maximum Likelihood (optional heteroskedasticity) model $$y_i = x_i^\\top \\beta + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2).$$ ln.var.v supplied, variance follows $$\\log(\\sigma_i^2) = w_i^\\top \\gamma_v,$$ otherwise \\(\\sigma_i^2 = \\sigma^2\\) constant (homoskedastic). function: Builds model frame X, y. Builds Zv log-variance index ln.var.v provided. Returns structured object placeholders coef, vcov, loglik. Insert MLE engine estimate \\(\\beta\\), (optionally) \\(\\sigma^2\\) \\(\\gamma_v\\); compute standard errors via AIM/OPG required vcetype.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/lm.mle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear Regression via MLE â€” lm.mle","text":"","code":"if (FALSE) { # \\dontrun{  library(snreg)  data(\"banks07\") head(banks07)  # Translog cost function specification spe.tl <- log(TC) ~ (log(Y1) + log(Y2) + log(W1) + log(W2))^2 +   I(0.5 * log(Y1)^2) + I(0.5 * log(Y2)^2) +   I(0.5 * log(W1)^2) + I(0.5 * log(W2)^2)  # ------------------------------------------------------------- # Specification 1: homoskedastic noise (ln.var.v = NULL) # ------------------------------------------------------------- formSV <- NULL  m1 <- lm.mle(   formula   = spe.tl,   data      = banks07,   ln.var.v  = formSV )  coef(m1)   # ------------------------------------------------------------- # Specification 2: heteroskedastic noise (variance depends on TA) # ------------------------------------------------------------- formSV <- ~ log(TA)  m2 <- lm.mle(   formula   = spe.tl,   data      = banks07,   ln.var.v  = formSV )  coef(m2)  } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/print.summary.snreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Summary of snreg Results â€” print.summary.snreg","title":"Print Summary of snreg Results â€” print.summary.snreg","text":"Prints contents \"summary.snreg\" object structured format. method reports convergence status (based gradient-Hessian scaling), log-likelihood, estimation results, â€”presentâ€”summaries technical/cost efficiencies marginal effects.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/print.summary.snreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Summary of snreg Results â€” print.summary.snreg","text":"","code":"# S3 method for class 'summary.snreg' print(obj, digits = NULL, ...)"},{"path":"https://olegbadunenko.github.io/snreg/reference/print.summary.snreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Summary of snreg Results â€” print.summary.snreg","text":"obj object class \"summary.snreg\" (produced summary.snreg). digits integer indicating number digits print; default NULL (internally set 4). ... additional arguments (currently unused).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/print.summary.snreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print Summary of snreg Results â€” print.summary.snreg","text":"input obj returned (invisibly) printing.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/print.summary.snreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Summary of snreg Results â€” print.summary.snreg","text":"Print Method Summary snreg Objects method expects fitted \"snreg\" object.","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/reference/residuals.snreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Residuals for snreg Objects â€” residuals.snreg","title":"Residuals for snreg Objects â€” residuals.snreg","text":"residuals.snreg S3 method extracting residuals fitted snreg model. Residuals may returned either full data estimation sample.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/residuals.snreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residuals for snreg Objects â€” residuals.snreg","text":"","code":"# S3 method for class 'snreg' residuals(obj, esample = TRUE, ...)"},{"path":"https://olegbadunenko.github.io/snreg/reference/residuals.snreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residuals for snreg Objects â€” residuals.snreg","text":"obj object class \"snreg\", typically produced snreg. esample logical. TRUE (default), residuals returned observations used estimation (others NA). FALSE, raw vector residuals (obj$resid) returned. ... additional arguments (currently unused).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/residuals.snreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Residuals for snreg Objects â€” residuals.snreg","text":"numeric vector residuals. esample = TRUE, vector matches length original data contains NA non-estimation observations. esample = FALSE, computed residuals returned.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/residuals.snreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Residuals for snreg Objects â€” residuals.snreg","text":"Extract Residuals snreg Model method simply accesses obj$resid component fitted \"snreg\" object. informative error produced residuals available.","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/reference/residuals.snreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Residuals for snreg Objects â€” residuals.snreg","text":"","code":"if (FALSE) { # \\dontrun{   m <- snreg(y ~ x1 + x2, data = df)    # Residuals for estimation sample only   residuals(m)    # Residuals for all observations   residuals(m, esample = FALSE) } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/snreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Regression with Skew-Normal Errors â€” snreg","title":"Linear Regression with Skew-Normal Errors â€” snreg","text":"snreg fits linear regression model disturbance term follows skew-normal distribution. function supports multiplicative heteroskedasticity noise variance via log-linear specification (ln.var.v) allows skewness parameter vary linearly exogenous variables (skew.v).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Regression with Skew-Normal Errors â€” snreg","text":"","code":"snreg(   formula,   data,   subset,   init.sk = NULL,   ln.var.v = NULL,   skew.v = NULL,   start.val = NULL,   technique = c(\"nr\"),   vcetype = c(\"aim\"),   lmtol = 1e-05,   reltol = 1e-12,   maxit = 199,   optim.report = 1,   optim.trace = 1,   print.level = 3,   digits = 4,   only.data = FALSE,   ... )"},{"path":"https://olegbadunenko.github.io/snreg/reference/snreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Regression with Skew-Normal Errors â€” snreg","text":"formula object class formula specifying regression: typically y ~ x1 + ..., y dependent variable x's regressors. data optional data.frame containing variables formula. found data, variables taken environment(formula). subset optional logical numeric vector specifying subset observations used estimation. init.sk numeric. Initial value (global) skewness parameter noise; can NULL skew.v supplied coefficients initialize. ln.var.v optional one-sided formula; e.g. ln.var.v ~ z1 + z2. Specifies exogenous variables entering (log) variance random noise component. NULL, noise variance homoskedastic. skew.v optional one-sided formula; e.g. skew.v ~ z3 + z4. Specifies exogenous variables determining skewness noise via linear index; NULL, skewness constant (scalar). start.val optional numeric vector starting values free parameters (regression coefficients, variance/heteroskedasticity parameters, skewness parameters). technique character vector giving preferred maximization routine(s) order preference. Currently recognized keywords include \"nr\" (Newtonâ€“Raphson), \"bhhh\", \"nm\" (Nelderâ€“Mead), \"bfgs\", \"cg\". scaffold implement yet, records choice. vcetype character specifying variance-covariance estimator type: \"aim\" approximated information matrix \"opg\" outer product gradients. Default \"aim\". lmtol numeric. Convergence tolerance based scaled gradient (applicable). Default 1e-5. reltol numeric. Relative convergence tolerance likelihood maximization. Default 1e-12. maxit integer. Maximum number iterations optimizer. Default 199. optim.report integer. Verbosity reporting progress (implemented). Default 1. optim.trace integer. positive, tracing information printed (implemented). Default 1. print.level integer. Printing level summaries: 1â€”print estimation results; 2â€”print optimization details; 3â€”print compact summary. Default 3. digits integer. Number digits printing. Default 4. .data logical. TRUE, function returns constructed model matrices design sets (estimation). Default FALSE. ... additional arguments reserved future methods (e.g., box constraints).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Regression with Skew-Normal Errors â€” snreg","text":"object class \"snreg\" containing maximum-likelihood results , depending optimization routine, additional diagnostics: par Numeric vector parameter estimates optimum. coef Named numeric vector equal par. vcov Varianceâ€“covariance matrix estimates. sds Standard errors, computed sqrt(diag(vcov)). ctab Coefficient table columns:         Estimate, Std.Err, Z value, Pr(>z). RSS Residual sum squares. esample Logical vector indicating observations used estimation. n Number observations used estimation sample. skewness Vector fitted skewness index. hessian (BFGS ) Observed Hessian optimum. vcetype == \"opg\",         set negative outer product individual gradients;         otherwise numerical Hessian computed. value (BFGS ) Objective value returned optim.         control$fnscale = -1, equals maximized log-likelihood. counts (BFGS ) Number iterations / function evaluations returned optim. convergence (BFGS ) Convergence code optim. message (BFGS ) Additional optim message, . ll Maximized log-likelihood value. gradient (NR ) Gradient solution. gg (NR ) Optional gradient-related diagnostic. gHg (NR ) Optional Newton-step diagnostic. theta_rel_ch (NR ) Relative parameter change metric across iterations. returned object class \"snreg\".","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear Regression with Skew-Normal Errors â€” snreg","text":"Linear Regression Skew-Normal Errors model $$y_i = x_i^\\top \\beta + \\varepsilon_i,\\quad \\varepsilon_i \\sim SN(0, \\sigma_i^2, \\alpha_i),$$ \\(SN\\) denotes skew-normal distribution (Azzalini). Heteroskedasticity noise variance (specified via ln.var.v) modeled $$\\log(\\sigma_i^2) = w_i^\\top \\gamma_v,$$ (optional) covariate-driven skewness (specified via skew.v) $$\\alpha_i = s_i^\\top \\delta.$$ function constructs model frame design matrices \\(\\beta\\), \\(\\gamma_v\\), \\(\\delta\\), designed paired maximum likelihood routine estimate parameters (optionally) asymptotic covariance via either AIM OPG.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snreg.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linear Regression with Skew-Normal Errors â€” snreg","text":"Azzalini, . (1985). Class Distributions Includes Normal Ones. Scandinavian Journal Statistics, 12(2), 171â€“178. Azzalini, ., & Capitanio, . (2014). Skew-Normal Related Families. Cambridge University Press.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear Regression with Skew-Normal Errors â€” snreg","text":"","code":"if (FALSE) { # \\dontrun{  library(snreg)  data(\"banks07\") head(banks07)  # Translog cost function spe.tl <- log(TC) ~ (log(Y1) + log(Y2) + log(W1) + log(W2))^2 +   I(0.5 * log(Y1)^2) + I(0.5 * log(Y2)^2) +   I(0.5 * log(W1)^2) + I(0.5 * log(W2)^2)   # ------------------------------------------------------------- # Specification 1: homoskedastic & symmetric noise # ------------------------------------------------------------- formSV <- NULL     # variance equation formSK <- NULL     # skewness equation  m1 <- snreg(   formula  = spe.tl,   data     = banks07,   ln.var.v = formSV,   skew.v   = formSK )  coef(m1)   # ------------------------------------------------------------- # Specification 2: heteroskedastic + skewed noise # ------------------------------------------------------------- formSV <- ~ log(TA)   # heteroskedasticity in v formSK <- ~ ER        # skewness driven by equity ratio  m2 <- snreg(   formula  = spe.tl,   data     = banks07,   ln.var.v = formSV,   skew.v   = formSK )  coef(m2)  } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/snsf.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","title":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","text":"snsf performs maximum likelihood estimation parameters technical cost efficiencies Stochastic Frontier Model skew-normally distributed error term.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snsf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","text":"","code":"snsf(   formula,   data,   subset,   distribution = \"e\",   prod = TRUE,   start.val = NULL,   init.sk = NULL,   ln.var.u = NULL,   ln.var.v = NULL,   skew.v = NULL,   mean.u = NULL,   technique = c(\"nr\"),   vcetype = c(\"aim\"),   optim.report = 1,   optim.trace = 1,   reltol = 1e-12,   lmtol = 1e-05,   maxit = 199,   print.level = 3,   report = 1,   trace = 1,   threads = 1,   only.data = FALSE,   digits = 4,   ... )"},{"path":"https://olegbadunenko.github.io/snreg/reference/snsf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","text":"formula object class formula specifying frontier: typical model y ~ x1 + ..., y log output (total cost), x's inputs (outputs input prices, logs). See Details. data optional data.frame containing variables formula. found data, variables taken environment(formula). subset optional logical numeric vector specifying subset observations model estimated efficiencies computed. distribution character scalar specifying distribution inefficiency term: default \"e\" (exponential). \"h\" (half-normal) \"t\" (truncated normal) implemented. prod logical. TRUE, estimates correspond stochastic production frontier technical efficiencies returned; FALSE, estimates correspond stochastic cost frontier cost efficiencies returned. Default TRUE. start.val optional numeric vector starting values optimizer. init.sk numeric. Initial value skewness parameter noise component; default 0.5. ln.var.u optional one-sided formula; e.g. ln.var.u = ~ z3 + z4. Specifies exogenous variables entering (log) variance inefficiency component. NULL, inefficiency variance homoskedastic, .e., \\(\\sigma_{u0}^2 = \\exp(\\gamma_{u0}[0])\\). ln.var.v optional one-sided formula; e.g. ln.var.v = ~ z1 + z2. Specifies exogenous variables entering (log) variance random noise component. NULL, noise variance homoskedastic, .e., \\(\\sigma_{v0}^2 = \\exp(\\gamma_{v0}[0])\\). skew.v optional one-sided formula; e.g. skew.v = ~ z5 + z6. Allows skewness noise depend linearly exogenous variables. NULL, skewness constant across units. mean.u optional one-sided formula; e.g. mean.u = ~ z7 + z8. Specifies whether mean pre-truncated normal distribution inefficiency term linear function exogenous variables. cross-sectional models, used distribution = \"t\". NULL, mean constant across units. implemented. optim.report integer. Verbosity level reporting optimization (implemented). Default 1. optim.trace integer. Trace level optimization (implemented). Default 1. reltol numeric. Relative convergence tolerance used maximizing log-likelihood optim. algorithm stops reduce objective factor reltol * (abs(val) + reltol) step. Default sqrt(.Machine$double.eps). lmtol numeric. Convergence tolerance based scaled gradient (applicable). Default 1e-5. maxit numeric. Maximum number iterations optimizer. Default 199. print.level integer. Printing level: 1â€”estimation results; 2â€”optimization details; 3â€”summary (cost/technical) efficiencies; 4â€”unit-specific point interval estimates efficiencies. Default 3. digits integer. Number digits displaying estimates efficiencies. Default 4. ... additional arguments passed internal methods optim, relevant (e.g., cost.eff.less.one = TRUE cost-frontier conventions). optim logical. TRUE, estimation proceeds via stats::optim; FALSE, internal routine (provided) used. Default FALSE. optim.method character. Method passed stats::optim optim = TRUE. Default \"bfgs\". optim.reltol numeric. Relative tolerance specifically optim; default 1e-8.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snsf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","text":"object class \"snreg\" maximum-likelihood estimates diagnostics: par Numeric vector ML parameter estimates optimum. coef Named numeric vector equal par. vcov Varianceâ€“covariance matrix estimates. sds Standard errors, sqrt(diag(vcov)). ctab Coefficient table columns         Coef., SE, z, P>|z|. ll Maximized log-likelihood value. hessian (computed) Observed Hessian OPG used form vcov. value (Optim-, aliasing) Objective value optim. counts (Optim-) Iteration evaluation counts optim. convergence Convergence code). message (Optim-) Message returned optim, . gradient (NR-) Gradient solution. gg (NR-) Gradient-related diagnostic. gHg (NR-) Newton-step diagnostic. theta_rel_ch (NR-) Relative parameter change metric across iterations. resid Regression residuals. RSS Residual sum squares crossprod(resid). shat2 Residual variance estimate var(resid). shat Residual standard deviation sqrt(shat2). aic Akaike Information Criterion. bic Bayesian Information Criterion. Mallows Mallows' \\(C_p\\)-like statistic. u Estimated inefficiency term (vector). Returned models         inefficiency component (e.g., exponential). eff Efficiency scores exp(-u) (technical cost, depending prod). sv Estimated (possibly unit-specific) standard deviation noise term. su Estimated (possibly unit-specific) standard deviation scale         inefficiency term. exponential models. skewness Estimated skewness index (e.g., skewness equation). esample Logical vector marking observations used estimation. n Number observations used. returned object class \"snreg\".","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snsf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","text":"Stochastic Frontier Model Skew-Normally Distributed Error Term Models snsf specified symbolically. typical model form y ~ x1 + ..., y represents logarithm outputs total costs {x1, ...} set inputs (production) outputs input prices (cost), typically logs. Options ln.var.u ln.var.v allow multiplicative heteroskedasticity inefficiency /noise components; .e., variances can modeled exponential functions exogenous variables (including intercept), Caudill et al. (1995).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snsf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","text":"Badunenko, O., & Henderson, D. J. (2023). Production analysis asymmetric noise. Journal Productivity Analysis, 61(1), 1â€“18. https://doi.org/10.1007/s11123-023-00680-5 Caudill, S. B., Ford, J. M., & Gropper, D. M. (1995). Frontier estimation firm-specific inefficiency measures presence heteroskedasticity. Journal Business & Economic Statistics, 13(1), 105â€“111.","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/reference/snsf.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","text":"Oleg Badunenko <Oleg.Badunenko.brunel.ac.uk>","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/snsf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stochastic Frontier Model with a Skew-Normally Distributed Error Term â€” snsf","text":"","code":"if (FALSE) { # \\dontrun{  library(snreg)  data(\"banks07\") head(banks07)  myprod <- FALSE  # Translog cost function spe.tl <- log(TC) ~ (log(Y1) + log(Y2) + log(W1) + log(W2))^2 +   I(0.5 * log(Y1)^2) + I(0.5 * log(Y2)^2) +   I(0.5 * log(W1)^2) + I(0.5 * log(W2)^2)   # ------------------------------------------------------------- # Specification 1: homoskedastic & symmetric # ------------------------------------------------------------- formSV <- NULL   # variance equation formSK <- NULL   # skewness equation formSU <- NULL   # inefficiency equation (unused here)  m1 <- snsf(   formula  = spe.tl,   data     = banks07,   prod     = myprod,   ln.var.v = formSV,   skew.v   = formSK )  coef(m1)   # ------------------------------------------------------------- # Specification 2: heteroskedastic + skewed noise # ------------------------------------------------------------- formSV <- ~ log(TA)      # heteroskedastic variance formSK <- ~ ER           # skewness driver formSU <- ~ LA + ER      # inefficiency  m2 <- snsf(   formula  = spe.tl,   data     = banks07,   prod     = myprod,   ln.var.v = formSV,   skew.v   = formSK )  coef(m2)  } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/su.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary Utility (su) â€” su","title":"Summary Utility (su) â€” su","text":"Computes compact table summary statistics variable vector, matrix, data frame. following metrics returned per variable: number observations (Obs), missing values (NAs), mean, standard deviation (StDev), interquartile range (IQR), minimum (Min), user-specified quantiles (probs), maximum (Max).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/su.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary Utility (su) â€” su","text":"","code":"su(   x,   mat.var.in.col = TRUE,   digits = 4,   probs = c(0.1, 0.25, 0.5, 0.75, 0.9),   print = FALSE )"},{"path":"https://olegbadunenko.github.io/snreg/reference/su.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary Utility (su) â€” su","text":"x numeric vector, matrix, data frame. matrices, variables assumed columns; set mat.var..col = FALSE treat rows variables. mat.var..col logical. TRUE (default), matrix interpreted variables columns. FALSE, matrix transposed rows treated variables. digits integer. Number digits use printing (affects printed output print = TRUE). Default 4. probs numeric vector probabilities \\([0, 1]\\) quantiles computed. Default c(0.1, 0.25, 0.5, 0.75, 0.9). print logical. TRUE, prints transposed summary table using specified number digits. Default FALSE.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/su.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary Utility (su) â€” su","text":"matrix (coercible data.frame) row corresponds variable columns contain summary statistics: Obs, NAs, Mean, StDev, IQR, Min, requested probs quantiles (named), Max. returned object given class \"snreg\" compatibility package-specific print/summarization methods.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/su.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary Utility (su) â€” su","text":"Compact Summary Statistics Vectors, Matrices, Data Frames Input handling: x matrix single row column, treated like vector.         Column row names used (available). Otherwise, default name created. x matrix multiple variables, variables taken columns.         Use mat.var..col = FALSE transpose treat rows variables. x vector, deparsed symbol name used variable name. x data frame, column summarized. Missing values excluded summary computations.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/su.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary Utility (su) â€” su","text":"","code":"if (FALSE) { # \\dontrun{   # Vector   set.seed(1)   v <- rnorm(100)   su(v, print = TRUE)    # Matrix: variables in columns   M <- cbind(x = rnorm(50), y = runif(50))   su(M)    # Matrix: variables in rows   Mr <- rbind(x = rnorm(50), y = runif(50))   su(Mr, mat.var.in.col = FALSE)    # Data frame   DF <- data.frame(a = rnorm(30), b = rexp(30), c = rbinom(30, 1, 0.3))   out <- su(DF)   head(out) } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/summary.snreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for Skew-Normal Regression Models â€” summary.snreg","title":"Summary for Skew-Normal Regression Models â€” summary.snreg","text":"Produces summary object objects class \"snreg\". function assigns class \"summary.snreg\" fitted model object, enabling dedicated print method (print.summary.snreg) display results structured format.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/summary.snreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for Skew-Normal Regression Models â€” summary.snreg","text":"","code":"# S3 method for class 'snreg' summary(obj, ...)"},{"path":"https://olegbadunenko.github.io/snreg/reference/summary.snreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for Skew-Normal Regression Models â€” summary.snreg","text":"obj object class \"snreg\", typically returned snreg. ... additional arguments (currently used).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/summary.snreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary for Skew-Normal Regression Models â€” summary.snreg","text":"object class \"summary.snreg\", identical input obj except class attribute.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/summary.snreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary for Skew-Normal Regression Models â€” summary.snreg","text":"Summary Method snreg Objects method expects fitted \"snreg\" object. summary.snreg modify contents object; updates class attribute \"summary.snreg\". corresponding print method (print.summary.snreg) responsible formatting displaying estimation details, convergence criteria, log-likelihood, coefficient tables, (present) heteroskedastic skewness components.","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/reference/summary.snreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary for Skew-Normal Regression Models â€” summary.snreg","text":"","code":"if (FALSE) { # \\dontrun{   # m <- snreg(TC ~ Y1 + Y2, data = banks07)   # s <- summary(m)   # print(s) } # }"},{"path":"https://olegbadunenko.github.io/snreg/reference/vcov.snreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract the Varianceâ€“Covariance Matrix â€” vcov.snreg","title":"Extract the Varianceâ€“Covariance Matrix â€” vcov.snreg","text":"vcov.snreg vcov S3 method objects class \"snreg\". returns model-based varianceâ€“covariance matrix stored fitted object.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/vcov.snreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract the Varianceâ€“Covariance Matrix â€” vcov.snreg","text":"","code":"# S3 method for class 'snreg' vcov(obj, ...)"},{"path":"https://olegbadunenko.github.io/snreg/reference/vcov.snreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract the Varianceâ€“Covariance Matrix â€” vcov.snreg","text":"obj object class \"snreg\", typically returned snreg. ... additional arguments (currently unused).","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/vcov.snreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract the Varianceâ€“Covariance Matrix â€” vcov.snreg","text":"numeric matrix containing varianceâ€“covariance estimated parameters.","code":""},{"path":"https://olegbadunenko.github.io/snreg/reference/vcov.snreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract the Varianceâ€“Covariance Matrix â€” vcov.snreg","text":"Varianceâ€“Covariance Matrix snreg Objects method expects fitted \"snreg\" object. method simply returns vcov component stored obj. estimator compute standard errors (e.g., estimation hasnâ€™t run yet scaffold), field may NULL, method error accordingly.","code":""},{"path":[]},{"path":"https://olegbadunenko.github.io/snreg/reference/vcov.snreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract the Varianceâ€“Covariance Matrix â€” vcov.snreg","text":"","code":"if (FALSE) { # \\dontrun{   library(snsf)    data(\"banks07\")   head(banks07)   # V <- vcov(m)   # diag(V) } # }"},{"path":"https://olegbadunenko.github.io/snreg/news/index.html","id":"snreg-100","dir":"Changelog","previous_headings":"","what":"snreg 1.0.0","title":"snreg 1.0.0","text":"first version package, functions computing average treatment effects","code":""},{"path":"https://olegbadunenko.github.io/snreg/news/index.html","id":"snreg-110","dir":"Changelog","previous_headings":"","what":"snreg 1.1.0","title":"snreg 1.1.0","text":"improvements functin detailed documentation","code":""}]
